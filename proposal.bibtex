@misc{Basili-etal:1994
    , author       = {V. Basili and G. Caldiera and H.D. Rombach}
    , title        = {The Goal Question Metric Approach}
    , year         = 1994
        , url          = {ftp://ftp.cs.umd.edu/pub/sel/papers/gqm.pdf}
}

@article{Blei-etal:2003,
    Author = {D. Blei and A. Ng and M. Jordan},
    Journal = {Journal of Machine Learning Research},
    Pages = {993--1022},
    Title = {Latent {D}irichlet allocation},
    Volume = 3,
    Year = 2003,
}

@article{Porter:1980,
    Author = {Porter, Martin F.},
    Journal = {Program: electronic library and information systems},
    Number = 3,
    Pages = {130--137},
    Title = {An algorithm for suffix stripping},
    Volume = 14,
    Year = 1980,
}

@inproceedings{Hindle-etal:2009,
    Author = {Hindle, Abram and Godfrey, Michael W. and Holt, Richard C.},
    Booktitle = {Proc.\ IEEE Int'l Conf.\ on Software Maintenance},
    Pages = {339--348},
    Title = {What's hot and what's not: Windowed developer topic analysis},
    Year = 2009,
}

@inproceedings{Bassett-Kraft:2013,
    Author = {Bassett, Blake and Kraft, Nicholas A.},
    Booktitle = {Proc.\ IEEE Int'l Conf.\ on Program Comprehension},
    Pages = {133--141},
    Title = {Structural information based term weighting in text retrieval for feature location},
    Year = 2013,
}

@inproceedings{Binkley-etal:2014,
    Author = {Binkley, David and Heinz, Daniel and Lawrie, Dawn and Overfelt, Justin},
    Title = {Understanding {LDA} in Source Code Analysis},
    Booktitle = {Proc.\ IEEE Int'l Conf.\ on Program Comprehension},
    Year = 2014,
    Pages = {26--36},
}

@inproceedings{Steyvers-etal:2004,
    author = {Steyvers, Mark and Smyth, Padhraic and Rosen-Zvi, Michal and Griffiths, Thomas},
    title = {Probabilistic Author-topic Models for Information Discovery},
    booktitle = {Proc.\ {ACM SIGKDD} Int'l Conf.\ on Knowledge Discovery and Data Mining},
    year = 2004,
    pages = {306--315},
}

@inproceedings{Rao-etal:2013,
    author = {Shivani Rao and Henry Medeiros and Avinash Kak},
    title = {An incremental update framework for efficient retrieval from software libraries for bug localization},
    booktitle ={Proc.\ Working Conf.\ on Reverse Engineering},
    year = 2013,
    pages = {62--71},
}

@inproceedings{Linstead-etal:2007,
    author = {Linstead, E. and Rigor, P. and Bajracharya, S. and Lopes, C. and Baldi, P.},
    booktitle = {Proc.\ Int'l Wksp.\ on Mining Software Repositories},
    pages = 30,
    title = {Mining Eclipse Developer Contributions via Author-Topic Models},
    year = 2007,
}

@inproceedings{Corley-etal:2012,
    author = {Corley, Christopher S. and Kammer, Elizabeth A. and Kraft, Nicholas A.},
    booktitle = {Proc.\ IEEE Int'l Conf.\ on Program Comprehension},
    pages = {173--182},
    title = {Modeling the ownership of source code topics},
    year = 2012,
}

@inproceedings{Biggers-etal:2011,
    author = {Biggers, Lauren R. and Eddy, Brian P. and Kraft, Nicholas A. and Etzkorn, Letha H.},
    booktitle = {Proc.\ IEEE Int'l Conf.\ on Software Maintenance},
    pages = {492--495},
    title = {Toward a metrics suite for source code lexicons},
    year = 2011,
}

@article{Biggers-etal:2014,
    title={Configuring latent {D}irichlet allocation based feature location},
    author={Biggers, Lauren R. and Bocovich, Cecylia and Capshaw, Riley and Eddy, Brian P. and Etzkorn, Letha H. and Kraft, Nicholas A.},
    journal={Empirical Software Engineering},
    volume= 19,
    number= 3,
    pages= {465--500},
    year= 2014,
}

@inproceedings{Zhai-Boyd-Graber:2013,
    Author = {Ke Zhai and Jordan Boyd-Graber},
    Booktitle = {Proc.\ Int'l Conf.\ on Machine Learning},
    Year = 2013,
    Title = {Online Topic Models with Infinite Vocabulary},
    volume = 28,
    number = 1,
    series = {JMLR: Workshop and Conference Proceedings},
    pages = {561--569},
}

@techreport{Biggers-etal:SERG-2012-03.R1,
    author = {Lauren R. Biggers and Brian P. Eddy and Nicholas A. Kraft},
    title = {A Comparison of Stemming Algorithms for Text Retrieval Based Feature Location},
    institution = {Department of Computer Science, The University of Alabama},
    year = 2013,
    month = apr,
    url = {http://software.eng.ua.edu/reports/SERG-2012-03},
    number = {SERG-2012-03.R1}
}

@inproceedings{Lukins-etal:2008,
    author = {Lukins, Stacy K. and Kraft, Nicholas A. and Etzkorn, Letha H.},
    title = {Source Code Retrieval for Bug Localization Using Latent Dirichlet Allocation},
    booktitle = {Proc.\ 15th Working Conf.\ on Reverse Engineering},
    year = 2008,
    pages = {155--164},
    doi = {10.1109/WCRE.2008.33},
}

@inproceedings{Rajlich-Wilde:2002,
    author = {Rajlich, V\'{a}clav and Wilde, Norman},
    title = {The Role of Concepts in Program Comprehension},
    booktitle = {Proc.\ 10th Int'l Wksp.\ on Program Comprehension},
    year = 2002,
    pages = 271,
}

@inproceedings{Linstead-etal:2007b,
    author = {Linstead, Erik and Rigor, Paul and Bajracharya, Sushil and Lopes, Cristina and Baldi, Pierre},
    title = {Mining Concepts from Code with Probabilistic Topic Models},
    booktitle = {Proc.\ 22nd IEEE/ACM Int'l Conf.\ on Automated Software Engineering},
    year = 2007,
    pages = {461--464},
    doi = {10.1145/1321631.1321709},
}

@inproceedings{Rosen-Zvi-etal:2004,
    author = {Rosen-Zvi, Michal and Griffiths, Thomas and Steyvers, Mark and Smyth, Padhraic},
    title = {The Author-topic Model for Authors and Documents},
    booktitle = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence},
    series = {UAI '04},
    year = {2004},
    isbn = {0-9749039-0-6},
    location = {Banff, Canada},
    pages = {487--494},
    numpages = {8},
    url = {http://dl.acm.org/citation.cfm?id=1036843.1036902},
    acmid = {1036902},
    publisher = {AUAI Press},
    address = {Arlington, Virginia, United States}
}

@inproceedings{Chang-etal:2009,
    title={Reading tea leaves: How humans interpret topic models},
    author={Chang, Jonathan and Gerrish, Sean and Wang, Chong and Boyd-graber, Jordan L and Blei, David M},
    booktitle={Advances in neural information processing systems},
    pages={288--296},
    year=2009,
}

% 69
@INPROCEEDINGS{Canini-etal:2009,
    author = {Kevin R. Canini and Lei Shi and Helen Wills Neuroscience and Thomas L. Griffiths},
    title = {Online inference of topics with latent Dirichlet allocation},
    booktitle = {In Proceedings of the International Conference on Artificial Intelligence and Statistics},
    year = {2009},
    url = {http://cocosci.berkeley.edu/tom/papers/topicpf.pdf}
}

% 70
@inproceedings{Hoffman-etal:2010,
    author    = {Matthew D. Hoffman and David M. Blei and Francis R. Bach},
    title     = {Online Learning for Latent {D}irichlet Allocation},
    booktitle = {Proc.\ 25th Annual Conf.\ on Neural Information Processing Systems},
    year      = 2010,
    pages     = {856--864},
}

% 71
@inproceedings{Blei-Lafferty:2006,
    author = {Blei, David M. and Lafferty, John D.},
    title = {Dynamic Topic Models},
    booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
    series = {ICML '06},
    year = {2006},
    isbn = {1-59593-383-2},
    location = {Pittsburgh, Pennsylvania},
    pages = {113--120},
    numpages = {8},
    url = {http://www.cs.cmu.edu/~lafferty/pub/dtm.pdf},
    doi = {10.1145/1143844.1143859},
    acmid = {1143859},
    publisher = {ACM},
    address = {New York, NY, USA},
}

% 72
@inproceedings{AlSumait-etal:2008,
    author = {AlSumait, Loulwah and Barbar\'{a}, Daniel and Domeniconi, Carlotta},
    title = {On-line LDA: Adaptive Topic Models for Mining Text Streams with Applications to Topic Detection and Tracking},
    booktitle = {Proceedings of the 2008 Eighth IEEE International Conference on Data Mining},
    series = {ICDM '08},
    year = {2008},
    isbn = {978-0-7695-3502-9},
    pages = {3--12},
    numpages = {10},
    url = {http://cs.gmu.edu/~carlotta/publications/AlsumaitL_onlineLDA.pdf},
    doi = {10.1109/ICDM.2008.140},
    acmid = {1511296},
    publisher = {IEEE Computer Society},
    address = {Washington, DC, USA},}

    % 73
    @article{Wang-etal:2012,
        author    = {Chong Wang and
            David M. Blei and
                David Heckerman},
        title     = {Continuous Time Dynamic Topic Models},
        journal   = {CoRR},
        volume    = {abs/1206.3298},
        year      = {2012},
        url = {https://www.cs.princeton.edu/~blei/papers/WangBleiHeckerman2008.pdf},
        bibsource = {DBLP, http://dblp.uni-trier.de}
    }

% 74
@inproceedings{Wang-McCallum:2006,
    author = {Wang, Xuerui and McCallum, Andrew},
    title = {Topics over Time: A non-Markov Continuous-time Model of Topical Trends},
    booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    series = {KDD '06},
    year = {2006},
    isbn = {1-59593-339-5},
    location = {Philadelphia, PA, USA},
    pages = {424--433},
    numpages = {10},
    url = {https://people.cs.umass.edu/~mccallum/papers/tot-kdd06.pdf},
    doi = {10.1145/1150402.1150450},
    acmid = {1150450},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {graphical models, temporal analysis, topic modeling},
}

% 91
@article{Linstead-etal:2008,
    author = {Erik Linstead and Cristina Lopes and Pierre Baldi},
    title = {An Application of Latent Dirichlet Allocation to Analyzing Software Evolution},
    journal ={Machine Learning and Applications, Fourth International Conference on},
    volume = {0},
    isbn = {978-0-7695-3495-4},
    year = {2008},
    pages = {813-818},
    doi = {http://doi.ieeecomputersociety.org/10.1109/ICMLA.2008.47},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
}

%92
@inproceedings{Thomas-etal:2011,
    author = {Thomas, Stephen W. and Adams, Bram and Hassan, Ahmed E. and Blostein, Dorothea},
    title = {Modeling the Evolution of Topics in Source Code Histories},
    booktitle = {Proc.\ 8th Working Conf.\ on Mining Software Repositories},
    year = 2011,
    pages = {173--182},
    doi = {10.1145/1985441.1985467},
}

% 123
@inproceedings{Abebe-etal:2009,
    author = {Abebe, Surafel Lemma and Haiduc, Sonia and Marcus, Andrian and Tonella, Paolo and Antoniol, Giuliano},
    title = {Analyzing the Evolution of the Source Code Vocabulary},
    booktitle = {Proceedings of the 2009 European Conference on Software Maintenance and Reengineering},
    series = {CSMR '09},
    year = {2009},
    isbn = {978-0-7695-3589-0},
    pages = {189--198},
    numpages = {10},
    url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4812752},
    doi = {10.1109/CSMR.2009.61},
    acmid = {1545438},
    publisher = {IEEE Computer Society},
    address = {Washington, DC, USA},
    keywords = {Lexicon evolution, Text mining, Software vocabulary},}

    % 124
    @article{Port-etal:2011,
        author = {Dan Port and Allen Nikora and Jairus Hihn and LiGuo Huang},
        title = {Experiences with text mining large collections of unstructured systems development artifacts at jpl},
        journal ={Software Engineering, International Conference on},
        volume = {},
        isbn = {978-1-4503-0445-0},
        year = {2011},
        pages = {701-710},
        doi = {http://doi.ieeecomputersociety.org/10.1145/1985793.1985891},
        url = {http://trs-new.jpl.nasa.gov/dspace/bitstream/2014/42005/1/11-0891.pdf},
        publisher = {IEEE Computer Society},
        address = {Los Alamitos, CA, USA},}



        @inproceedings{Rao-etal:2011,
            author = {Rao, Shivani and Kak, Avinash},
            title = {Retrieval from Software Libraries for Bug Localization: A Comparative Study of Generic and Composite Text Models},
            booktitle = {Proceedings of the 8th Working Conference on Mining Software Repositories},
            series = {MSR '11},
            year = {2011},
            isbn = {978-1-4503-0574-7},
            location = {Waikiki, Honolulu, HI, USA},
            pages = {43--52},
            numpages = {10},
            url = {http://doi.acm.org/10.1145/1985441.1985451},
            doi = {10.1145/1985441.1985451},
            acmid = {1985451},
            publisher = {ACM},
            address = {New York, NY, USA},
            keywords = {bug localization, information retrieval, latent dirichlet allocation, latent semantic analysis, software engineering},
        }

@INPROCEEDINGS{Zhou-etal:2012,
    author={Jian Zhou and Hongyu Zhang and Lo, D.},
    booktitle={Software Engineering (ICSE), 2012 34th International Conference on},
    title={Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports},
    year={2012},
    month={June},
    pages={14-24},
    keywords={information retrieval;program debugging;public domain software;software quality;BugLocator;bug reports;information retrieval based method;information retrieval-based bug localization;open source projects;rVSM;revised vector space model;software quality;software system;source code files;textual similarity;Computational modeling;Computer bugs;Equations;Indexing;Information retrieval;Mathematical model;Vectors;bug localization;bug reports;feature location;information retrieval},
    doi={10.1109/ICSE.2012.6227210},
    ISSN={0270-5257},}

    @INPROCEEDINGS{Sisman-etal:2013,
        author={Sisman, B. and Kak, A.C.},
        booktitle={Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on},
        title={Assisting code search with automatic Query Reformulation for bug localization},
        year={2013},
        month={May},
        pages={309-318},
        keywords={document handling;program debugging;query processing;software metrics;automatic QR;automatic query reformulation;bug localization performance improvement;code base;code search;highest-ranked artifact retrieval;initial query;natural language document retrieval;positional proximity;query design;similarity metric;software artifact retrieval;software engineering tasks;software projects;source code retrieval;under-the-hood operation;user search query;Animation;Context;Measurement;Search engines;Software;Software libraries;Strips;Bug Localization;Pseudo Relevance Feedback;Query Expansion;Query Reformulation;Software Maintenance},
        doi={10.1109/MSR.2013.6624044},
        ISSN={2160-1852},}

        @INPROCEEDINGS{Haiduc-etal:2011,
            author={Haiduc, S.},
            booktitle={Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on},
            title={Automatically detecting the quality of the query and its implications in IR-based concept location},
            year={2011},
            month={Nov},
            pages={637-640},
            keywords={query processing;software maintenance;information retrieval-based concept location;lexical information;program comprehension activities;query quality;software maintenance;source code;Conferences;Correlation;Estimation;Measurement;Prediction algorithms;Search engines;concept location;information retrieval;program comprehension;query;search;source code},
            doi={10.1109/ASE.2011.6100144},
            ISSN={1938-4300},}


            @inproceedings{Maskeri-etal:2008,
                author = {Maskeri, Girish and Sarkar, Santonu and Heafield, Kenneth},
                title = {Mining Business Topics in Source Code Using Latent Dirichlet Allocation},
                booktitle = {Proceedings of the 1st India Software Engineering Conference},
                series = {ISEC '08},
                year = {2008},
                isbn = {978-1-59593-917-3},
                location = {Hyderabad, India},
                pages = {113--120},
                numpages = {8},
                url = {http://doi.acm.org/10.1145/1342211.1342234},
                doi = {10.1145/1342211.1342234},
                acmid = {1342234},
                publisher = {ACM},
                address = {New York, NY, USA},
                keywords = {LDA, maintenance, program comprehension},
            }


@INPROCEEDINGS{Tian-etal:2009,
    author={Kai Tian and Revelle, M. and Poshyvanyk, D.},
    booktitle={Mining Software Repositories, 2009. MSR '09. 6th IEEE International Working Conference on},
    title={Using Latent Dirichlet Allocation for automatic categorization of software},
    year={2009},
    month={May},
    pages={163-166},
    keywords={C language;information retrieval;public domain software;software architecture;software libraries;C language;LACT technique;MUDABlue;automatic categorization software system;information retrieval method;latent Dirichlet allocation;open-source repository;probabilistic topic model;programming language;software architecture;software library;source code document;Computer architecture;Computer languages;Information analysis;Information retrieval;Java;Manuals;Open source software;Performance evaluation;Software libraries;Software systems},
    doi={10.1109/MSR.2009.5069496},}

    @INPROCEEDINGS{Gethers-etal:2011,
        author={Gethers, M. and Savage, T. and Di Penta, M. and Oliveto, R. and Poshyvanyk, D. and De Lucia, A.},
        booktitle={Software Engineering (ICSE), 2011 33rd International Conference on},
        title={CodeTopics: which topic am I coding now?},
        year={2011},
        month={May},
        pages={1034-1036},
        keywords={reverse engineering;software quality;software tools;CodeTopics;Eclipse plug-in;high-level artifacts;source code artifacts comprehension;source code identifier quality;Educational institutions;Games;Information retrieval;Java;Monopoly;Object oriented modeling;Software;program comprehension;source code lexicon;traceability},
        doi={10.1145/1985793.1985988},
        ISSN={0270-5257},}

        @inproceedings{Bernardi-etal:2011,
            author = {Bernardi, Mario Luca and Sementa, Carmine and Zagarese, Quirino and Distante, Damiano and Di Penta, Massimiliano},
            title = {What Topics Do Firefox and Chrome Contributors Discuss?},
            booktitle = {Proceedings of the 8th Working Conference on Mining Software Repositories},
            series = {MSR '11},
            year = {2011},
            isbn = {978-1-4503-0574-7},
            location = {Waikiki, Honolulu, HI, USA},
            pages = {234--237},
            numpages = {4},
            url = {http://doi.acm.org/10.1145/1985441.1985480},
            doi = {10.1145/1985441.1985480},
            acmid = {1985480},
            publisher = {ACM},
            address = {New York, NY, USA},
            keywords = {bug reports, co-evolution, text mining, topic mining},
        }

@inproceedings{Andrzejewski-etal:2007,
    author = {Andrzejewski, David and Mulhern, Anne and Liblit, Ben and Zhu, Xiaojin},
    title = {Statistical Debugging Using Latent Topic Models},
    booktitle = {Proceedings of the 18th European Conference on Machine Learning},
    series = {ECML '07},
    year = {2007},
    isbn = {978-3-540-74957-8},
    location = {Warsaw, Poland},
    pages = {6--17},
    numpages = {12},
    url = {http://dx.doi.org/10.1007/978-3-540-74958-5_5},
    doi = {10.1007/978-3-540-74958-5_5},
    acmid = {1421672},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg},
}

@inproceedings{Zimmermann-etal:2007,
    author = {Zimmermann, Thomas and Premraj, Rahul and Zeller, Andreas},
    title = {Predicting Defects for Eclipse},
    booktitle = {Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
    series = {PROMISE '07},
    year = {2007},
    isbn = {0-7695-2954-2},
    pages = {9--},
    url = {http://dx.doi.org/10.1109/PROMISE.2007.10},
    doi = {10.1109/PROMISE.2007.10},
    acmid = {1269057},
    publisher = {IEEE Computer Society},
    address = {Washington, DC, USA},
}

@inproceedings{Canfora-etal:2006,
    author = {Canfora, Gerardo and Cerulo, Luigi},
    title = {Fine Grained Indexing of Software Repositories to Support Impact Analysis},
    booktitle = {Proceedings of the 2006 International Workshop on Mining Software Repositories},
    series = {MSR '06},
    year = {2006},
    isbn = {1-59593-397-2},
    location = {Shanghai, China},
    pages = {105--111},
    numpages = {7},
    url = {http://doi.acm.org/10.1145/1137983.1138009},
    doi = {10.1145/1137983.1138009},
    acmid = {1138009},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {impact analysis, mining software repositories},
}


@inproceedings{Wang-etal:2008,
    author = {wang, xiaoyin and zhang, lu and xie, tao and anvik, john and sun, jiasu},
    title = {an approach to detecting duplicate bug reports using natural language and execution information},
    booktitle = {proceedings of the 30th international conference on software engineering},
    series = {icse '08},
    year = {2008},
    isbn = {978-1-60558-079-1},
    location = {leipzig, germany},
    pages = {461--470},
    numpages = {10},
    url = {http://doi.acm.org/10.1145/1368088.1368151},
    doi = {10.1145/1368088.1368151},
    acmid = {1368151},
    publisher = {acm},
    address = {new york, ny, usa},
    keywords = {duplicate bug report, execution information, information retrieval},
}


@inproceedings{Dallmeier-etal:2007,
    author = {Dallmeier, Valentin and Zimmermann, Thomas},
    title = {Extraction of Bug Localization Benchmarks from History},
    booktitle = {Proceedings of the Twenty-second IEEE/ACM International Conference on Automated Software Engineering},
    series = {ASE '07},
    year = {2007},
    isbn = {978-1-59593-882-4},
    location = {Atlanta, Georgia, USA},
    pages = {433--436},
    numpages = {4},
    url = {http://doi.acm.org/10.1145/1321631.1321702},
    doi = {10.1145/1321631.1321702},
    acmid = {1321702},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {benchmarking, defect localization},
}

@techreport{moreBugs,
    title = {{moreBugs: A {N}ew {D}ataset for
        {B}enchmarking {A}lgorithms for
        {I}nformation {R}etrieval from
        {S}oftware {R}epositories} (TR-ECE-13-07)},
    author = {Shivani Rao and Avinash Kak},
    year = {2013},
    institution = {Purdue University,
        School of Electrical and
            Computer Engineering},
    month = {04},
    Date-Added = {2013-04-23},
}


@inproceedings{Marcus-etal:2004,
    author       = {A. Marcus and A. Sergeyev and V. Rajlich and J.I. Maletic},
    title        = {An Information Retrieval Approach to Concept Location in Source Code},
    booktitle    = {Proc.\ 11th Working Conf.\ on Reverse Engineering},
    year         = 2004,
    pages        = {214--223},
}
@inproceedings{Marcus-Menzies:2010,
    author       = {A. Marcus and T. Menzies},
    title        = {Software is data too},
    booktitle    = {Proc.\ of the FSE/SDP Wksp.\ on Future of Software Engineering Research},
    year         = 2010,
    pages        = {229--232},
}

@article{Deerwester-etal:1990,
    title={Indexing by latent semantic analysis},
    author={Deerwester, Scott C. and Dumais, Susan T. and Landauer, Thomas K. and Furnas, George W. and Harshman, Richard A.},
    journal={J.\ Am.\ Soc.\ Inf.\ Sci.},
    volume=41,
    number=6,
    pages={391--407},
    year={1990},
    doi={10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9},
}

@article{Salton:1988,
    author = {Salton, Gerard and Buckley, Christopher},
    title = {Term-weighting Approaches in Automatic Text Retrieval},
    journal = {Inf.\ Process.\ Manage.},
    volume = 24,
    number = 5,
    year = 1988,
    pages = {513--523},
    doi = {10.1016/0306-4573(88)90021-0},
}

@book{Salton:1971,
    author = {Salton, G.},
    title = {The SMART Retrieval System --- Experiments in Automatic Document Processing},
    year = {1971},
    publisher = {Prentice-Hall},
}

@inproceedings{Gensim,
      title = {{Software Framework for Topic Modelling with Large Corpora}},
      author = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
      booktitle = {{Proceedings of the LREC 2010 Workshop on New
           Challenges for NLP Frameworks}},
      pages = {45--50},
      year = 2010,
      month = May,
      day = 22,
      publisher = {ELRA},
      address = {Valletta, Malta},
      language={English}
}

@inproceedings{Chuang-etal:2012,
    title={Termite: Visualization techniques for assessing textual topic models},
    author={Chuang, Jason and Manning, Christopher D and Heer, Jeffrey},
    booktitle={Proc.\ Int'l Working Conf.\ on Advanced Visual Interfaces},
    pages={74--77},
    year={2012},
}

@inproceedings{Wei-etal:2010,
    title={{TIARA}: a visual exploratory text analytic system},
    author={Wei, Furu and Liu, Shixia and Song, Yangqiu and Pan, Shimei and Zhou, Michelle X. and Qian, Weihong and Shi, Lei and Tan, Li and Zhang, Qiang},
    booktitle={Proc.\ 16th {ACM SIGKDD} Int'l Conf.\ on Knowledge Discovery and Data Mining},
    pages={153--162},
    year={2010},
}

@incollection{StopWords
    , author    = {C. Fox}
    , title     = {Lexical Analysis and Stoplists}
    , booktitle = {Information Retrieval: Data Structures and Algorithms}
    , year      = 1992
        , editor    = {W.B. Frakes and R. Baeza-Yates}
    , publisher = {Prentice-Hall}
    , isbn      = {0-13-463837-9}
}

@inproceedings{Hindle-etal:2012,
    author = {A. Hindle and C. Bird and T. Zimmerman and N. Nagappan},
    title = {Relating requirements to implementation via topic analysis: Do topics extracted from requirements make sense to managers and developers?},
    booktitle = {Proc.\ 28th IEEE Int'l Conf.\ on Software Maintenance},
    pages = {243--252},
    year = 2012,
    doi = {10.1109/ICSM.2012.6405278},
}

@inproceedings{Hall-etal:2008,
    title = {Studying the history of ideas using topic models},
    author = {D. Hall and D. Jurafsky and C.D. Manning},
    booktitle = {Proc.\ Conf.\ on Empirical Methods in Natural Language Processing},
    pages = {363--371},
    year = 2008,
}

@inproceedings{Steyvers2004Probabilistic,
    abstract = {{We propose a new unsupervised learning technique for extracting information from large text collections. We model documents as if they were generated by a two-stage stochastic process. Each author is represented by a probability distribution over topics, and each topic is represented as a probability distribution over words for that topic. The words in a multi-author paper are assumed to be the result of a mixture of each authors' topic mixture. The topic-word and author-topic distributions are learned from data in an unsupervised manner using a Markov chain Monte Carlo algorithm. We apply the methodology to a large corpus of 160,000 abstracts and 85,000 authors from the well-known CiteSeer digital library, and learn a model with 300 topics. We discuss in detail the interpretation of the results discovered by the system including specific topic and author models, ranking of authors by topic and topics by author, significant trends in the computer science literature between 1990 and 2002, parsing of abstracts by topics and authors and detection of unusual papers by specific authors. An online query interface to the model is also discussed that allows interactive exploration of author-topic models for corpora such as CiteSeer.}},
    address = {New York, NY, USA},
    author = {Steyvers, Mark and Smyth, Padhraic and Zvi, Michal R. and Griffiths, Thomas},
    booktitle = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {378119},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1014087},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1014052.1014087},
    doi = {10.1145/1014052.1014087},
    isbn = {1-58113-888-1},
    keywords = {q},
    location = {Seattle, WA, USA},
    pages = {306--315},
    posted-at = {2012-08-22 20:39:56},
    priority = {2},
    publisher = {ACM},
    series = {KDD '04},
    title = {{Probabilistic author-topic models for information discovery}},
    url = {http://dx.doi.org/10.1145/1014052.1014087},
    year = {2004}
}

@inproceedings{Collard2003XMLbased,
    abstract = {{A lightweight fact extractor is presented that utilizes XML tools, such as XPath and XSLT to extract static information from C++ source code programs. The source code is first converted into an XML representation, srcML, to facilitate the use of a wide variety of XML tools. The method is deemed lightweight because only a partial parsing of the source is done. Additionally, the technique is quite robust and can be applied to incomplete and noncompilable source code. The trade off to this approach is that queries on some low level details cannot be directly addressed. This approach is applied to a fact extractor benchmark as comparison with other, heavier weight, fact extractors. Fact extractors are widely used to support understanding tasks associated with maintenance, reverse engineering and various other software engineering tasks.}},
    author = {Collard, M. L. and Kagdi, H. H. and Maletic, J. I.},
    booktitle = {Program Comprehension, 2003. 11th IEEE International Workshop on},
    citeulike-article-id = {10799072},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/WPC.2003.1199197},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1199197},
    doi = {10.1109/WPC.2003.1199197},
    institution = {Dept. of Comput. Sci., Kent State Univ., OH, USA},
    isbn = {0-7695-1883-4},
    issn = {1092-8138},
    keywords = {q},
    location = {Portland, OR, USA},
    month = may,
    pages = {134--143},
    posted-at = {2012-08-21 01:55:34},
    priority = {2},
    publisher = {IEEE},
    title = {{An XML-based lightweight C++ fact extractor}},
    url = {http://dx.doi.org/10.1109/WPC.2003.1199197},
    year = {2003}
}

@inproceedings{Guo2010Characterizing,
    abstract = {{We performed an empirical study to characterize factors that affect which bugs get fixed in Windows Vista and Windows 7, focusing on factors related to bug report edits and relationships between people involved in handling the bug. We found that bugs reported by people with better reputations were more likely to get fixed, as were bugs handled by people on the same team and working in geographical proximity. We reinforce these quantitative results with survey feedback from 358 Microsoft employees who were involved in Windows bugs. Survey respondents also mentioned additional qualitative influences on bug fixing, such as the importance of seniority and interpersonal skills of the bug reporter. Informed by these findings, we built a statistical model to predict the probability that a new bug will be fixed (the first known one, to the best of our knowledge). We trained it on Windows Vista bugs and got a precision of 68\% and recall of 64\% when predicting Windows 7 bug fixes. Engineers could use such a model to prioritize bugs during triage, to estimate developer workloads, and to decide which bugs should be closed or migrated to future product versions.}},
    address = {New York, NY, USA},
    author = {Guo, Philip J. and Zimmermann, Thomas and Nagappan, Nachiappan and Murphy, Brendan},
    booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1},
    citeulike-article-id = {7262107},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806799.1806871},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806799.1806871},
    doi = {10.1145/1806799.1806871},
    isbn = {978-1-60558-719-6},
    keywords = {q},
    location = {Cape Town, South Africa},
    pages = {495--504},
    posted-at = {2012-08-20 14:42:42},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '10},
    title = {{Characterizing and predicting which bugs get fixed: an empirical study of Microsoft Windows}},
    url = {http://dx.doi.org/10.1145/1806799.1806871},
    year = {2010}
}

@inproceedings{Guo2011Not,
    abstract = {{Bug reporting/fixing is an important social part of the soft-ware development process. The bug-fixing process inher-ently has strong inter-personal dynamics at play, especially in how to find the optimal person to handle a bug report. Bug report reassignments, which are a common part of the bug-fixing process, have rarely been studied. In this paper, we present a large-scale quantitative and qualitative analysis of the bug reassignment process in the Microsoft Windows Vista operating system project. We quantify social interactions in terms of both useful and harmful reassignments. For instance, we found that reassignments are useful to determine the best person to fix a bug, contrary to the popular opinion that reassignments are always harmful. We categorized five primary reasons for reassignments: finding the root cause, determining ownership, poor bug report quality, hard to determine proper fix, and workload balancing. We then use these findings to make recommendations for the design of more socially-aware bug tracking systems that can overcome some of the inefficiencies we observed in our study.}},
    address = {New York, NY, USA},
    author = {Guo, Philip J. and Zimmermann, Thomas and Nagappan, Nachiappan and Murphy, Brendan},
    booktitle = {Proceedings of the ACM 2011 conference on Computer supported cooperative work},
    citeulike-article-id = {9974113},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1958887},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1958824.1958887},
    doi = {10.1145/1958824.1958887},
    isbn = {978-1-4503-0556-3},
    keywords = {q},
    location = {Hangzhou, China},
    pages = {395--404},
    posted-at = {2012-08-20 14:13:54},
    priority = {2},
    publisher = {ACM},
    series = {CSCW '11},
    title = {{"Not my bug!" and other reasons for software bug report reassignments}},
    url = {http://dx.doi.org/10.1145/1958824.1958887},
    year = {2011}
}

@inproceedings{Somasundaram2012Automatic,
    abstract = {{Software developers, particularly in open-source projects, rely on bug repositories to organize their work. On a bug report, the component field is used to indicate to which team of developers a bug should be routed. Researchers have shown that incorrect categorization of newly received bug reports to components can cause potential delays in the resolution of bug reports. Approaches have been developed that consider the use of machine learning approaches, specifically Support Vector Machines (svm), to automatically categorize bug reports into the appropriate component to help streamline the process of solving a bug. One drawback of an SVM-based approach is that the results of categorization can be uneven across various components in the system if some components receive less reports than others. In this paper, we consider broadening the consistency of the recommendations produced by an automatic approach by investigating three approaches to automating bug report categorization: an approach similar to previous ones based on an SVM classifier and Term Frequency Inverse Document Frequency(svm-tf-idf), an approach using Latent Dirichlet Allocation (LDA) with SVM (svm-lda) and an approach using LDA and Kullback Leibler divergence (lda-kl). We found that lda-kl produced recalls similar to those found previously but with better consistency across all components for which bugs must be categorized.}},
    address = {New York, NY, USA},
    author = {Somasundaram, Kalyanasundaram and Murphy, Gail C.},
    booktitle = {Proceedings of the 5th India Software Engineering Conference},
    citeulike-article-id = {11092733},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2134254.2134276},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2134254.2134276},
    doi = {10.1145/2134254.2134276},
    isbn = {978-1-4503-1142-7},
    keywords = {q},
    location = {Kanpur, India},
    pages = {125--130},
    posted-at = {2012-08-19 13:24:12},
    priority = {2},
    publisher = {ACM},
    series = {ISEC '12},
    title = {{Automatic categorization of bug reports using latent Dirichlet allocation}},
    url = {http://dx.doi.org/10.1145/2134254.2134276},
    year = {2012}
}

@article{Blei2003Latent,
    abstract = {{We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.}},
    address = {Cambridge, MA, USA},
    author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
    citeulike-article-id = {353473},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=944937},
    citeulike-linkout-1 = {http://dx.doi.org/10.1162/jmlr.2003.3.4-5.993},
    doi = {10.1162/jmlr.2003.3.4-5.993},
    issn = {1532-4435},
    journal = {J. Mach. Learn. Res.},
    keywords = {q, topics},
    month = mar,
    number = {4-5},
    pages = {993--1022},
    posted-at = {2012-08-15 03:43:35},
    priority = {2},
    publisher = {JMLR.org},
    title = {{Latent dirichlet allocation}},
    url = {http://dx.doi.org/10.1162/jmlr.2003.3.4-5.993},
    volume = {3},
    year = {2003}
}

@inproceedings{Corley2012Modeling,
    abstract = {{Exploring linguistic topics in source code is a program comprehension activity that shows promise in helping a developer to become familiar with an unfamiliar software system. Examining ownership in source code can reveal complementary information, such as who to contact with questions regarding a source code entity, but the relationship between linguistic topics and ownership is an unexplored area. In this paper we combine software repository mining and topic modeling to measure the ownership of linguistic topics in source code. We conduct an exploratory study of the relationship between linguistic topics and ownership in source code using 10 open source Java systems. We find that classes that belong to the same linguistic topic tend to have similar ownership characteristics, which suggests that conceptually related classes often share the same owner(s). We also find that similar topics tend to share the same ownership characteristics, which suggests that the same developers own related topics.}},
    author = {Corley, C. S. and Kammer, E. A. and Kraft, N. A.},
    booktitle = {Program Comprehension (ICPC), 2012 IEEE 20th International Conference on},
    citeulike-article-id = {11067341},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICPC.2012.6240485},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6240485},
    doi = {10.1109/ICPC.2012.6240485},
    institution = {Dept. of Comput. Sci., Univ. of Alabama, Tuscaloosa, AL, USA},
    isbn = {978-1-4673-1213-4},
    issn = {1063-6897},
    keywords = {expertise, ownership, q, topics},
    month = jun,
    pages = {173--182},
    posted-at = {2012-08-15 03:22:20},
    priority = {2},
    publisher = {IEEE},
    title = {{Modeling the ownership of source code topics}},
    url = {http://dx.doi.org/10.1109/ICPC.2012.6240485},
    year = {2012}
}

@book{Beck2001Extreme,
    abstract = {{Kent Beck's <I>eXtreme Programming eXplained</I> provides an intriguing high-level overview of the author's Extreme Programming (XP) software development methodology. Written for IS managers, project leaders, or programmers, this guide provides a glimpse at the principles behind XP and its potential advantages for small- to mid-size software development teams.<p> The book intends to describe what XP is, its guiding principles, and how it works. Simply written, the book avoids case studies and concrete details in demonstrating the efficacy of XP. Instead, it demonstrates how XP relies on simplicity, unit testing, programming in pairs, communal ownership of code, and customer input on software to motivate code improvement during the development process. As the author notes, these principles are not new, but when they're combined their synergy fosters a new and arguably better way to build and maintain software. Throughout the book, the author presents and explains these principles, such as "rapid feedback" and "play to win," which form the basis of XP.<p> Generally speaking, XP changes the way programmers work. The book is good at delineating new roles for programmers and managers who Beck calls "coaches." The most striking characteristic of XP is that programmers work in pairs, and that testing is an intrinsic part of the coding process. In a later section, the author even shows where XP works and where it doesn't and offers suggestions for migrating teams and organizations over to the XP process. <p> In the afterword, the author recounts the experiences that led him to develop and refine XP, an insightful section that should inspire any organization to adopt XP. This book serves as a useful introduction to the philosophy and practice of XP for the manager or programmer who wants a potentially better way to build software. <I>--Richard Dragan</I><p> <B>Topics covered</B>: Extreme Programming (XP) software methodology, principles, XP team roles, facilities design, testing, refactoring, the XP software lifecycle, and adopting XP.} {Software development projects can be fun, productive, and even daring.  Yet they can consistently deliver value to a business and remain under control.  <P>Extreme Programming (XP) was conceived and developed to address the specific needs of software development conducted by small teams in the face of vague and changing requirements. This new lightweight methodology challenges many conventional tenets, including the long-held assumption that the cost of changing a piece of software necessarily rises dramatically over the course of time.  XP recognizes that projects have to work to achieve this reduction in cost and exploit the savings once they have been earned.  <P>Fundamentals of XP include:  <P>* Distinguishing between the decisions to be made by business interests and those to be made by project stakeholders. * Writing unit tests before programming and keeping all of the tests running at all times. * Integrating and testing the whole system-several times a day. * Producing all software in pairs, two programmers at one screen. * Starting projects with a simple design that constantly evolves to add needed flexibility and remove unneeded complexity. * Putting a minimal system into production quickly and growing it in whatever directions prove most valuable.  <P>Why is XP so controversial?  Some sacred cows don't make the cut in XP:  <P>* Don't force team members to specialize and become analysts, architects, programmers, testers, and integrators-every XP programmer participates in all of these critical activities every day. * Don't conduct complete up-front analysis and design-an XP project starts with a quick analysis of the entire system, and XP programmers continue to make analysis and design decisions throughout development. * Develop infrastructure and frameworks as you develop your application, not up-front-delivering business value is the heartbeat that drives XP projects. * Don't write and maintain implementation documentation-communication in XP projects occurs face-to-face, or through efficient tests and carefully written code.  <P>You may love XP or you may hate it, but Extreme Programming Explained will force you to take a fresh look at how you develop software.}},
    author = {Beck, Kent},
    citeulike-article-id = {149388},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0201616416},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0201616416},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/249369335},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0201616416},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0201616416},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0201616416/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201616416},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0201616416},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0201616416},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0201616416\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0201616416},
    day = {05},
    edition = {US ed},
    howpublished = {Paperback},
    isbn = {0201616416},
    keywords = {agile, extreme, programming, q, xp},
    month = oct,
    posted-at = {2012-08-14 09:54:47},
    priority = {2},
    publisher = {Addison-Wesley},
    title = {{Extreme programming explained: embrace change}},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201616416},
    year = {2001}
}

@inproceedings{Poshyvanyk2007Combining,
    abstract = {{The paper addresses the problem of concept location in source code by presenting an approach which combines formal concept analysis (FCA) and latent semantic indexing (LSI). In the proposed approach, LSI is used to map the concepts expressed in queries written by the programmer to relevant parts of the source code, presented as a ranked list of search results. Given the ranked list of source code elements, our approach selects most relevant attributes from these documents and organizes the results in a concept lattice, generated via FCA. The approach is evaluated in a case study on concept location in the source code of eclipse, an industrial size integrated development environment. The results of the case study show that the proposed approach is effective in organizing different concepts and their relationships present in the subset of the search results. The proposed concept location method outperforms the simple ranking of the search results, reducing the programmers' effort.}},
    address = {Washington, DC, USA},
    author = {Poshyvanyk, D. and Marcus, A.},
    booktitle = {15th IEEE International Conference on Program Comprehension (ICPC '07)},
    citeulike-article-id = {6609657},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1271345},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICPC.2007.13},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4268239},
    doi = {10.1109/ICPC.2007.13},
    institution = {Dept. of Comput. Sci., Wayne State Univ., Detroit, MI},
    isbn = {0-7695-2860-0},
    issn = {1063-6897},
    keywords = {q},
    location = {Banff, Alberta, BC},
    month = jun,
    pages = {37--48},
    posted-at = {2012-07-29 14:38:24},
    priority = {2},
    publisher = {IEEE},
    title = {{Combining Formal Concept Analysis with Information Retrieval for Concept Location in Source Code}},
    url = {http://dx.doi.org/10.1109/ICPC.2007.13},
    year = {2007}
}

@inproceedings{Linares-Vasquez2012Triaging,
    abstract = {{ Not available. }},
    author = {Linares-Vasquez, Mario and Hossen, Kamal and Dang, Hoang and Kagdi, Huzefa and Gethers, Malcom and Poshyvanyk, Denys},
    citeulike-article-id = {10942389},
    keywords = {q},
    posted-at = {2012-07-26 15:48:10},
    priority = {2},
    publisher = {IEEE},
    title = {{Triaging Incoming Change Requets: Bug or Commit History, or Code Authorship?}},
    year = {2012}
}

@article{ieee610,
    citeulike-article-id = {10942388},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/IEEESTD.1990.101064},
    doi = {10.1109/IEEESTD.1990.101064},
    journal = {IEEE Std 610.12-1990},
    keywords = {ieee, q, std},
    pages = {1},
    posted-at = {2012-07-26 15:48:09},
    priority = {2},
    title = {{IEEE Standard Glossary of Software Engineering Terminology}},
    url = {http://dx.doi.org/10.1109/IEEESTD.1990.101064},
    year = {1990}
}

@article{iso14764,
    author = {Iso},
    citeulike-article-id = {10942387},
    journal = {ISO/IEC 14764:2006 (E) IEEE Std 14764-2006 Revision of IEEE Std 1219-1998)},
    keywords = {evolution, q},
    posted-at = {2012-07-26 15:48:09},
    priority = {2},
    title = {International Standard - {ISO}/{IEC} 14764 {IEEE} Std 14764-2006},
    year = {2006}
}

@inproceedings{Ackerman1998Considering,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Ackerman, Mark S. and Halverson, Christine},
    booktitle = {Proceedings of the 1998 ACM conference on Computer supported cooperative work},
    citeulike-article-id = {4070904},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=289444.289461},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/289444.289461},
    doi = {10.1145/289444.289461},
    isbn = {1-58113-009-0},
    keywords = {q},
    location = {Seattle, Washington, United States},
    pages = {39--48},
    posted-at = {2012-07-26 15:16:54},
    priority = {2},
    publisher = {ACM},
    series = {CSCW '98},
    title = {{Considering an organization's memory}},
    url = {http://dx.doi.org/10.1145/289444.289461},
    year = {1998}
}

@inproceedings{Canfora2005Impact,
    abstract = {{Impact analysis is the identification of the work products affected by a proposed change request, either a bug fix or a new feature request. In many open-source projects, such as KDE, Gnome, Mozilla, Openoffice, change requests, and related data, are stored in a bug tracking system such as Bugzilla. These data, together with the data stored in a versioning system, such as CVS, are a valuable source of information on which useful analyses can be performed. In this paper we propose a method to derive the set of source files impacted by a proposed change request. The method exploits information retrieval algorithms to link the change request description and the set of historical source file revisions impacted by similar past change requests. The method is evaluated by applying it on four open-source projects}},
    author = {Canfora, G. and Cerulo, L.},
    booktitle = {11th IEEE International Software Metrics Symposium (METRICS'05)},
    citeulike-article-id = {5208098},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/METRICS.2005.28},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1509307},
    doi = {10.1109/METRICS.2005.28},
    isbn = {0-7695-2371-4},
    journal = {Software Metrics, 2005. 11th IEEE International Symposium},
    keywords = {q},
    location = {Como, Italy},
    pages = {29},
    posted-at = {2012-07-24 19:55:08},
    priority = {2},
    publisher = {IEEE},
    title = {{Impact Analysis by Mining Software and Change Request Repositories}},
    url = {http://dx.doi.org/10.1109/METRICS.2005.28},
    year = {2005}
}

@inproceedings{Canfora2006Fine,
    abstract = {{Versioned and bug-tracked software systems provide a huge amount of historical data regarding source code changes and issues management. In this paper we deal with impact analysis of a change request and show that data stored in software repositories are a good descriptor on how past change requests have been resolved. A fine grained analysis method of software repositories is used to index code at different levels of granularity, such as lines of code and source files, with free text contained in software repositories. The method exploits information retrieval algorithms to link the change request description and code entities impacted by similar past change requests. We evaluate such approach on a set of three open-source projects.}},
    address = {New York, NY, USA},
    author = {Canfora, Gerardo and Cerulo, Luigi},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {3064729},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1138009},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138009},
    doi = {10.1145/1137983.1138009},
    isbn = {1-59593-397-2},
    keywords = {q},
    location = {Shanghai, China},
    pages = {105--111},
    posted-at = {2012-07-24 19:54:27},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {{Fine grained indexing of software repositories to support impact analysis}},
    url = {http://dx.doi.org/10.1145/1137983.1138009},
    year = {2006}
}

@inproceedings{Fischer2003Analyzing,
    abstract = {{First Page of the Article}},
    author = {Fischer, M. and Pinzger, M. and Gall, H.},
    booktitle = {10th Working Conference on Reverse Engineering, 2003. WCRE 2003. Proceedings.},
    citeulike-article-id = {8300658},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/WCRE.2003.1287240},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1287240},
    doi = {10.1109/WCRE.2003.1287240},
    isbn = {0-7695-2027-8},
    keywords = {q},
    location = {Victoria, BC, Canada},
    pages = {90--99},
    posted-at = {2012-07-24 19:52:59},
    priority = {2},
    publisher = {IEEE},
    title = {{Analyzing and relating bug report data for feature tracking}},
    url = {http://dx.doi.org/10.1109/WCRE.2003.1287240},
    year = {2003}
}

@inproceedings{Fischer2003Populating,
    abstract = {{Version control and bug tracking systems contain large amounts of historical information that can give deep insight into the evolution of a software project. Unfortunately, these systems provide only insufficient support for a detailed analysis of software evolution aspects. We address this problem and introduce an approach for populating a release history database that combines version data with bug tracking data and adds missing data not covered by version control systems such as merge points. Then simple queries can be applied to the structured data to obtain meaningful views showing the evolution of a software project. Such views enable more accurate reasoning of evolutionary aspects and facilitate the anticipation of software evolution. We demonstrate our approach on the large open source project Mozilla that offers great opportunities to compare results and validate our approach.}},
    author = {Fischer, M. and Pinzger, M. and Gall, H.},
    booktitle = {International Conference on Software Maintenance, 2003. ICSM 2003. Proceedings.},
    citeulike-article-id = {320069},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICSM.2003.1235403},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1235403},
    doi = {10.1109/ICSM.2003.1235403},
    isbn = {0-7695-1905-9},
    issn = {1063-6773},
    journal = {Software Maintenance, 2003. ICSM 2003. Proceedings. International Conference on},
    keywords = {q},
    location = {Amsterdam, Netherlands},
    pages = {23--32},
    posted-at = {2012-07-24 19:51:38},
    priority = {2},
    publisher = {IEEE Comput. Soc},
    title = {{Populating a Release History Database from version control and bug tracking systems}},
    url = {http://dx.doi.org/10.1109/ICSM.2003.1235403},
    year = {2003}
}

@inproceedings{Tsunoda2006Analyzing,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Tsunoda, Masateru and Monden, Akito and Kakimoto, Takeshi and Kamei, Yasutaka and Matsumoto, Ken I.},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {10896164},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1138031},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138031},
    doi = {10.1145/1137983.1138031},
    isbn = {1-59593-397-2},
    keywords = {q},
    location = {Shanghai, China},
    pages = {181--182},
    posted-at = {2012-07-24 19:50:38},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {{Analyzing OSS developers' working time using mailing lists archives}},
    url = {http://dx.doi.org/10.1145/1137983.1138031},
    year = {2006}
}

@inproceedings{Podgurski2003Automated,
    abstract = {{This paper proposes automated support for classifying reported software failures in order to facilitate prioritizing them and diagnosing their causes. A classification strategy is presented that involves the use of supervised and unsupervised pattern classification and multivariate visualization. These techniques are applied to profiles of failed executions in order to group together failures with the same or similar causes. The resulting classification is then used to assess the frequency and severity of failures caused by particular defects and to help diagnose those defects. The results of applying the proposed classification strategy to failures of three large subject programs are reported These results indicate that the strategy can be effective.}},
    address = {Los Alamitos, CA, USA},
    author = {Podgurski, A. and Leon, D. and Francis, P. and Masri, W. and Minch, M. and Sun, Jiayang and Wang, Bin},
    booktitle = {25th International Conference on Software Engineering, 2003. Proceedings.},
    citeulike-article-id = {9401193},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICSE.2003.1201224},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICSE.2003.1201224},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1201224},
    doi = {10.1109/ICSE.2003.1201224},
    isbn = {0-7695-1877-X},
    issn = {0270-5257},
    journal = {Software Engineering, International Conference on},
    keywords = {q},
    location = {Portland, OR, USA},
    pages = {465--475},
    posted-at = {2012-07-22 01:56:36},
    priority = {2},
    publisher = {IEEE},
    title = {{Automated support for classifying software failure reports}},
    url = {http://dx.doi.org/10.1109/ICSE.2003.1201224},
    volume = {0},
    year = {2003}
}

@inproceedings{Dang2012ReBucket,
    abstract = {{Software often crashes. Once a crash happens, a crash report could be sent to software developers for investigation upon user permission. To facilitate efficient handling of crashes, crash reports received by Microsoft's Windows Error Reporting (WER) system are organized into a set of  ” buckets”. Each bucket contains duplicate crash reports that are deemed as manifestations of the same bug. The bucket information is important for prioritizing efforts to resolve crashing bugs. To improve the accuracy of bucketing, we propose ReBucket, a method for clustering crash reports based on call stack matching. ReBucket measures the similarities of call stacks in crash reports and then assigns the reports to appropriate buckets based on the similarity values. We evaluate ReBucket using crash data collected from five widely-used Microsoft products. The results show that ReBucket achieves better overall performance than the existing methods. On average, the F-measure obtained by ReBucket is about 0.88.}},
    author = {Dang, Yingnong and Wu, Rongxin and Zhang, Hongyu and Zhang, Dongmei and Nobel, Peter},
    booktitle = {2012 34th International Conference on Software Engineering (ICSE)},
    citeulike-article-id = {10903997},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICSE.2012.6227111},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6227111},
    doi = {10.1109/ICSE.2012.6227111},
    isbn = {978-1-4673-1067-3},
    keywords = {bugs, q},
    location = {Zurich, Switzerland},
    month = jun,
    pages = {1084--1093},
    posted-at = {2012-07-19 22:04:38},
    priority = {2},
    publisher = {IEEE},
    title = {{ReBucket: A method for clustering duplicate crash reports based on call stack similarity}},
    url = {http://dx.doi.org/10.1109/ICSE.2012.6227111},
    year = {2012}
}

@inproceedings{Linstead2007Mining,
    abstract = {{We present the results of applying statistical author-topic models to a subset of the Eclipse 3.0 source code consisting of 2,119 source files and 700,000 lines of code from 59 developers. This technique provides an intuitive and automated framework with which to mine developer contributions and competencies from a given code base while simultaneously extracting software function in the form of topics. In addition to serving as a convenient summary for program function and developer activities, our study shows that topic models provide a meaningful, effective, and statistical basis for developer similarity analysis.}},
    address = {Washington, DC, USA},
    author = {Linstead, Erik and Rigor, Paul and Bajracharya, Sushil and Lopes, Cristina and Baldi, Pierre},
    booktitle = {Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)},
    citeulike-article-id = {4406357},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1268983.1269044},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2007.20},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228667},
    doi = {10.1109/MSR.2007.20},
    isbn = {0-7695-2950-X},
    keywords = {q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {30},
    posted-at = {2012-07-17 22:27:19},
    priority = {2},
    publisher = {IEEE},
    title = {{Mining Eclipse Developer Contributions via Author-Topic Models}},
    url = {http://dx.doi.org/10.1109/MSR.2007.20},
    year = {2007}
}

@inproceedings{DiLucca2002Approach,
    abstract = {{When a software system critical for an organization exhibits a problem during its operation, it is relevant to fix it in a short period of time, to avoid serious economical losses. The problem is therefore noticed by the organization in charge of the maintenance, and it should be correctly and quickly dispatched to the right maintenance team. We propose to automatically classify incoming maintenance requests (also said tickets), routing them to specialized maintenance teams. The final goal is to develop a router working around the clock, that, without human intervention, dispatches incoming tickets with the lowest misclassification error, measured with respect to a given routing policy. 6000 maintenance tickets from a large, multi-site, software system, spanning about two years of system in-field operation, were used to compare and assess the accuracy of different classification approaches (i.e., Vector Space model, Bayesian model, support vectors, classification trees and k-nearest neighbor classification). The application and the tickets were divided into eight areas and pre-classified by human experts. Preliminary results were encouraging, up to 84\% of the incoming tickets were correctly classified.}},
    author = {Di Lucca, G. A. and Di Penta, M. and Gradara, S.},
    booktitle = {International Conference on Software Maintenance, 2002. Proceedings.},
    citeulike-article-id = {10896317},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICSM.2002.1167756},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1167756},
    doi = {10.1109/ICSM.2002.1167756},
    isbn = {0-7695-1819-2},
    keywords = {q},
    location = {Montreal, Que., Canada},
    pages = {93--102},
    posted-at = {2012-07-17 22:25:32},
    priority = {2},
    publisher = {IEEE Comput. Soc},
    title = {{An approach to classify software maintenance requests}},
    url = {http://dx.doi.org/10.1109/ICSM.2002.1167756},
    year = {2002}
}

@inproceedings{Canfora2005How,
    abstract = {{In open source development, software evolution tasks are usually managed with a bug tracker system, such as Bugzilla [1], and a versioning system, such as CVS [2]. This provides for a huge amount of historical data regarding bug resolutions and new enhancement feature implementations. We discuss how software repositories can help developers in managing a new change request, either a bug or an enhancement feature. The hypothesis is that data stored in software repositories are a good descriptor on how past change requests have been resolved. Textual descriptions of fixed change requests stored in software repositories, both Bugzilla and CVS, are used to index developers and source files as documents in an information retrieval system. For a new change request, such indexes can be useful to identify the most appropriate developers to resolve it, or to predict the set of impacted source files. 1.}},
    author = {Canfora, Gerardo and Cerulo, Luigi},
    booktitle = {In Workshop on Empirical Studies in Reverse Engineering},
    citeulike-article-id = {10896315},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.3646},
    keywords = {q},
    posted-at = {2012-07-17 22:23:56},
    priority = {2},
    title = {{How software repositories can help in resolving a new change request}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.3646},
    year = {2005}
}

@inproceedings{Anvik2006Automating,
    abstract = {{Open-source development projects typically support an open bug repository to which both developers and users can report bugs. A report that appears in this repository must be triaged to determine if the report is one which requires attention and if it is, which developer will be assigned the responsibility of resolving the report. Large open-source developments are burdened by the rate at which new bug reports appear in the bug repository. The thesis of this work is that the task of triage can be eased by using a semi-automated approach to assign bug reports to developers. The approach consists of constructing a recommender for bug assignments; examined are both a range of algorithms that can be used and the various kinds of information provided to the algorithms. The proposed work seeks to determine through human experimentation a sufficient level of precision for the recommendations, and to analytically determine the trade-offs of the various algorithmic and information choices.}},
    address = {New York, NY, USA},
    author = {Anvik, John},
    booktitle = {Proceedings of the 28th international conference on Software engineering},
    citeulike-article-id = {10896311},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134285.1134457},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1134285.1134457},
    doi = {10.1145/1134285.1134457},
    isbn = {1-59593-375-1},
    keywords = {q},
    location = {Shanghai, China},
    pages = {937--940},
    posted-at = {2012-07-17 22:21:43},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '06},
    title = {{Automating bug report assignment}},
    url = {http://dx.doi.org/10.1145/1134285.1134457},
    year = {2006}
}

@inproceedings{Bettenburg2008Extracting,
    abstract = {{In software engineering experiments, the description of bug reports is typically treated as natural language text, although it often contains stack traces, source code, and patches. Neglecting such structural elements is a loss of valuable information; structure usually leads to a better performance of machine learning approaches. In this paper, we present a tool called infoZilla that detects structural elements from bug reports with near perfect accuracy and allows us to extract them. We anticipate that infoZilla can be used to leverage data from bug reports at a different granularity level that can facilitate interesting research in the future.}},
    address = {New York, NY, USA},
    author = {Bettenburg, Nicolas and Premraj, Rahul and Zimmermann, Thomas and Kim, Sunghun},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {10896310},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370757},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370757},
    doi = {10.1145/1370750.1370757},
    isbn = {978-1-60558-024-1},
    keywords = {q},
    location = {Leipzig, Germany},
    pages = {27--30},
    posted-at = {2012-07-17 22:20:13},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{Extracting structural information from bug reports}},
    url = {http://dx.doi.org/10.1145/1370750.1370757},
    year = {2008}
}

@inproceedings{Hindle2008What,
    abstract = {{Research in the mining of software repositories has frequently ignored commits that include a large number of files (we call these large commits). The main goal of this paper is to understand the rationale behind large commits, and if there is anything we can learn from them. To address this goal we performed a case study that included the manual classification of large commits of nine open source projects. The contributions include a taxonomy of large commits, which are grouped according to their intention. We contrast large commits against small commits and show that large commits are more perfective while small commits are more corrective. These large commits provide us with a window on the development practices of maintenance teams.}},
    address = {New York, NY, USA},
    author = {Hindle, Abram and German, Daniel M. and Holt, Ric},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {5014733},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370773},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370773},
    doi = {10.1145/1370750.1370773},
    isbn = {978-1-60558-024-1},
    keywords = {q},
    location = {Leipzig, Germany},
    pages = {99--108},
    posted-at = {2012-07-17 22:19:13},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{What do large commits tell us?: a taxonomical study of large commits}},
    url = {http://dx.doi.org/10.1145/1370750.1370773},
    year = {2008}
}

@inproceedings{Alonso2008Expertise,
    abstract = {{As software evolves over time, the identification of expertise becomes an important problem. Component ownership and team awareness of such ownership are signals of solid project. Ownership and ownership awareness are also issues in open-source software (OSS) projects. Indeed, the membership in OSS projects is dynamic with team members arriving and leaving. In large open source projects, specialists who know the system very well are considered experts. How can one identify the experts in a project by mining a particular repository like the source code? Have they gotten help from other people? We provide an approach using classification of the source code tree as a path to derive the expertise of the committers. Because committers may get help from other people, we also retrieve their contributors. We also provide a visualization that helps to further explore the repository via committers and categories. We present a prototype implementation that describes our research using the Apache HTTP Web server project as a case study.}},
    address = {New York, NY, USA},
    author = {Alonso, Omar and Devanbu, Premkumar T. and Gertz, Michael},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {4672764},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370780},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370780},
    doi = {10.1145/1370750.1370780},
    isbn = {978-1-60558-024-1},
    keywords = {q},
    location = {Leipzig, Germany},
    pages = {125--128},
    posted-at = {2012-07-17 22:17:43},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{Expertise identification and visualization from CVS}},
    url = {http://dx.doi.org/10.1145/1370750.1370780},
    year = {2008}
}

@inproceedings{Gousios2008Measuring,
    abstract = {{Apart from source code, software infrastructures supporting agile and distributed software projects contain traces of developer activity that does not directly affect the product itself but is important for the development process. We propose a model that, by combining traditional contribution metrics with data mined from software repositories, can deliver accurate developer contribution measurements. The model creates clusters of similar projects to extract weights that are then applied to the actions a developer performed on project assets to extract a combined measurement of the developer's contribution. We are currently implementing the model in the context of a software quality monitoring system while we are also validating its components by means of questionnaires.}},
    address = {New York, NY, USA},
    author = {Gousios, Georgios and Kalliamvakou, Eirini and Spinellis, Diomidis},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {10668682},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370750.1370781},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370781},
    doi = {10.1145/1370750.1370781},
    isbn = {978-1-60558-024-1},
    keywords = {q},
    location = {Leipzig, Germany},
    pages = {129--132},
    posted-at = {2012-07-17 22:16:22},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{Measuring developer contribution from software repository data}},
    url = {http://dx.doi.org/10.1145/1370750.1370781},
    year = {2008}
}

@inproceedings{Siy2008Summarizing,
    abstract = {{Temporal segmentation partitions time series data with the intent of producing more homogeneous segments. It is a technique used to preprocess data so that subsequent time series analysis on individual segments can detect trends that may not be evident when performing time series analysis on the entire dataset. This technique allows data miners to partition a large dataset without making any assumption of periodicity or any other a priori knowledge of the dataset's features. We investigate the insights that can be gained from the application of time series segmentation to software version repositories. Software version repositories from large projects contain on the order of hundreds of thousands of timestamped entries or more. It is a continuing challenge to aggregate such data so that noise is reduced and important characteristics are brought out. In this paper, we present a way to summarize developer work history in terms of the files they have modified over time by segmenting the CVS change data of individual Eclipse developers. We show that the files they modify tends to change significantly over time though most of them tend to work within the same directories.}},
    address = {New York, NY, USA},
    author = {Siy, Harvey and Chundi, Parvathi and Subramaniam, Mahadevan},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {10896305},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370784},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370784},
    doi = {10.1145/1370750.1370784},
    isbn = {978-1-60558-024-1},
    keywords = {q},
    location = {Leipzig, Germany},
    pages = {137--140},
    posted-at = {2012-07-17 22:14:56},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{Summarizing developer work history using time series segmentation: challenge report}},
    url = {http://dx.doi.org/10.1145/1370750.1370784},
    year = {2008}
}

@inproceedings{Fritz2007Does,
    abstract = {{The practice of software development can likely be improved if an externalized model of each programmer's knowledge of a particular code base is available. Some tools already assume a useful form of such a model can be created from data collected during development, such as expertise recommenders that use information about who has changed each file to suggest who might answer questions about particular parts of a system. In this paper, we report on an empirical study that investigates whether a programmer's activity can be used to build a model of what a programmer knows about a code base. In this study, nineteen professional Java programmers completed a series of questionnaires about the code on which they were working. These questionnaires were generated automatically and asked about program elements a programmer had worked with frequently and recently and ones that he had not. We found that a degree of interest model based on this frequency and recency of interaction can often indicate the parts of the code base for which the programmer has knowledge. We also determined a number of factors that may be used to improve the model, such as authorship of program elements, the role of elements, and the task being performed.}},
    address = {New York, NY, USA},
    author = {Fritz, Thomas and Murphy, Gail C. and Hill, Emily},
    booktitle = {Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
    citeulike-article-id = {2823097},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1287673},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1287624.1287673},
    doi = {10.1145/1287624.1287673},
    isbn = {978-1-59593-811-4},
    keywords = {expertise, q},
    location = {Dubrovnik, Croatia},
    pages = {341--350},
    posted-at = {2012-07-17 22:12:15},
    priority = {2},
    publisher = {ACM},
    series = {ESEC-FSE '07},
    title = {{Does a programmer's activity indicate knowledge of code?}},
    url = {http://dx.doi.org/10.1145/1287624.1287673},
    year = {2007}
}

@inproceedings{Halverson2006Designing,
    abstract = {{Software development tools primarily focus on supporting the technical work. Yet no matter the tools employed, the process followed, or the size of the team, important aspects of development are non-technical, and largely unsupported. For example, increasing distribution of development teams highlights the issues of coordination and cooperation. This paper focuses on one area: managing change requests. Interviews with industry and open-source programmers were used to create designs for the visual inspection of change requests. This paper presents fieldwork findings and two designs. We conclude by reflecting on the issues that task visualizations that support social inferences address in software development.}},
    address = {New York, NY, USA},
    author = {Halverson, Christine A. and Ellis, Jason B. and Danis, Catalina and Kellogg, Wendy A.},
    booktitle = {Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work},
    citeulike-article-id = {966549},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1180883},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1180875.1180883},
    doi = {10.1145/1180875.1180883},
    isbn = {1-59593-249-6},
    keywords = {bugs, q},
    location = {Banff, Alberta, Canada},
    pages = {39--48},
    posted-at = {2012-07-17 21:47:13},
    priority = {2},
    publisher = {ACM},
    series = {CSCW '06},
    title = {{Designing task visualizations to support the coordination of work in software development}},
    url = {http://dx.doi.org/10.1145/1180875.1180883},
    year = {2006}
}

@inproceedings{DAmbros2007A,
    abstract = {{Visualization has long been accepted as a viable means to comprehend large amounts of information. Especially in the context of software evolution a well-designed visualization is crucial to be able to cope with the sheer data that needs to be analyzed. Many approaches have been investigated to visualize evolving systems, but most of them focus on structural data and are useful to answer questions about the structural evolution of a system. In this paper we consider an often neglected type of information, namely the one provided by bug tracking systems, which store data about the problems that various people, from developers to end users, detected and reported. We first briefly introduce the context by reporting on the particularities of the present data, and then propose two visualizations to render bugs as first-level entities.}},
    author = {D'Ambros, Marco and Lanza, Michele and Pinzger, Martin},
    booktitle = {2007 4th IEEE International Workshop on Visualizing Software for Understanding and Analysis},
    citeulike-article-id = {10896274},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/VISSOF.2007.4290709},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4290709},
    doi = {10.1109/VISSOF.2007.4290709},
    isbn = {1-4244-0599-8},
    keywords = {bugs, q},
    location = {Banff, AB, Canada},
    month = jun,
    pages = {113--120},
    posted-at = {2012-07-17 21:45:55},
    priority = {2},
    publisher = {IEEE},
    title = {{"A Bug's Life" Visualizing a Bug Database}},
    url = {http://dx.doi.org/10.1109/VISSOF.2007.4290709},
    year = {2007}
}

@inproceedings{Weiss2007How,
    abstract = {{Predicting the time and effort for a software problem has long been a difficult task. We present an approach that automatically predicts the fixing effort, i.e., the person-hours spent on fixing an issue. Our technique leverages existing issue tracking systems: given a new issue report, we use the Lucene framework to search for similar, earlier reports and use their average time as a prediction. Our approach thus allows for early effort estimation, helping in assigning issues and scheduling stable releases. We evaluated our approach using effort data from the JBoss project. Given a sufficient number of issues reports, our automatic predictions are close to the actual effort; for issues that are bugs, we are off by only one hour, beating na\^{A}¨\'{y}ve predictions by a factor of four.}},
    address = {Washington, DC, USA},
    author = {Weiss, Cathrin and Premraj, Rahul and Zimmermann, Thomas and Zeller, Andreas},
    booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
    citeulike-article-id = {2516366},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1268983.1269017},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2007.13},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228638},
    doi = {10.1109/MSR.2007.13},
    isbn = {0-7695-2950-X},
    keywords = {bugs, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {1},
    posted-at = {2012-07-17 21:44:56},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {MSR '07},
    title = {{How Long Will It Take to Fix This Bug?}},
    url = {http://dx.doi.org/10.1109/MSR.2007.13},
    year = {2007}
}

@inproceedings{Panjer2007Predicting,
    abstract = {{In non-trivial software development projects planning and allocation of resources is an important and difficult task. Estimation of work time to fix a bug is commonly used to support this process. This research explores the viability of using data mining tools to predict the time to fix a bug given only the basic information known at the beginning of a bug's lifetime. To address this question, a historical portion of the Eclipse Bugzilla database is used for modeling and predicting bug lifetimes. A bug history transformation process is described and several data mining models are built and tested. Interesting behaviours derived from the models are documented. The models can correctly predict up to 34.9\% of the bugs into a discretized log scaled lifetime class.}},
    address = {Washington, DC, USA},
    author = {Panjer, Lucas D.},
    booktitle = {Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)},
    citeulike-article-id = {2211420},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1268983.1269043},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2007.25},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228666},
    doi = {10.1109/MSR.2007.25},
    isbn = {0-7695-2950-X},
    keywords = {bugs, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {29},
    posted-at = {2012-07-17 21:44:07},
    priority = {2},
    publisher = {IEEE},
    title = {{Predicting Eclipse Bug Lifetimes}},
    url = {http://dx.doi.org/10.1109/MSR.2007.25},
    year = {2007}
}

@inproceedings{Bettenburg2008What,
    abstract = {{In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are at the same time most difficult to provide for users. Such insight is helpful to design new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. In our experiments, CUEZILLA was able to predict the quality of 31--48\% of bug reports accurately.}},
    address = {New York, NY, USA},
    author = {Bettenburg, Nicolas and Just, Sascha and Schr\"{o}ter, Adrian and Weiss, Cathrin and Premraj, Rahul and Zimmermann, Thomas},
    booktitle = {Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering},
    citeulike-article-id = {9972760},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1453146},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1453101.1453146},
    doi = {10.1145/1453101.1453146},
    isbn = {978-1-59593-995-1},
    keywords = {bugs, q},
    location = {Atlanta, Georgia},
    pages = {308--318},
    posted-at = {2012-07-17 21:42:09},
    priority = {2},
    publisher = {ACM},
    series = {SIGSOFT '08/FSE-16},
    title = {{What makes a good bug report?}},
    url = {http://dx.doi.org/10.1145/1453101.1453146},
    year = {2008}
}

@article{vanderAalst2004Workflow,
    abstract = {{Contemporary workflow management systems are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a complicated time-consuming process and, typically, there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, we have developed techniques for discovering workflow models. The starting point for such techniques is a so-called "workflow log" containing information about the workflow process as it is actually being executed. We present a new algorithm to extract a process model from such a log and represent it in terms of a Petri net. However, we also demonstrate that it is not possible to discover arbitrary workflow processes. We explore a class of workflow processes that can be discovered. We show that the α-algorithm can successfully mine any workflow represented by a so-called SWF-net.}},
    address = {Los Alamitos, CA, USA},
    author = {van der Aalst, W. and Weijters, T. and Maruster, L.},
    booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
    citeulike-article-id = {2605320},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2004.47},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TKDE.2004.47},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1316839},
    doi = {10.1109/TKDE.2004.47},
    issn = {1041-4347},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    keywords = {data\_mining, q},
    month = sep,
    number = {9},
    pages = {1128--1142},
    posted-at = {2012-07-17 21:41:00},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{Workflow mining: discovering process models from event logs}},
    url = {http://dx.doi.org/10.1109/TKDE.2004.47},
    volume = {16},
    year = {2004}
}

@inproceedings{Silva2005Probabilistic,
    abstract = {{In several organizations, it has become increasingly popular to document and log the steps that makeup a typical business process. In some situations, a normative workflow model of such processes is developed, and it becomes important to know if such a model is actually being followed by analyzing the available activity logs. In other scenarios, no model is available and, with the purpose of evaluating cases or creating new production policies, one is interested in learning a workflow representation of such activities. In either case, machine learning tools that can mine workflow models are of great interest and still relatively unexplored. We present here a probabilistic workflow model and a corresponding learning algorithm that runs in polynomial time. We illustrate the algorithm on example data derived from a real world workflow.}},
    address = {New York, NY, USA},
    author = {Silva, Ricardo and Zhang, Jiji and Shanahan, James G.},
    booktitle = {Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining},
    citeulike-article-id = {10896264},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1081903},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1081870.1081903},
    doi = {10.1145/1081870.1081903},
    isbn = {1-59593-135-X},
    keywords = {data\_mining, q},
    location = {Chicago, Illinois, USA},
    pages = {275--284},
    posted-at = {2012-07-17 21:39:42},
    priority = {2},
    publisher = {ACM},
    series = {KDD '05},
    title = {{Probabilistic workflow mining}},
    url = {http://dx.doi.org/10.1145/1081870.1081903},
    year = {2005}
}

@incollection{Agrawal1998Mining,
    abstract = {{Modern enterprises increasingly use the workflow paradigm to prescribe how business processes should be performed. Processes are typically modeled as annotated activity graphs. We present an approach for a system that constructs process models from logs of past, unstructured executions of the given process. The graph so produced conforms to the dependencies and past executions present in the log. By providing models that capture the previous executions of the process, this technique allows easier introduction of a workflow system and evaluation and evolution of existing process models. We also present results from applying the algorithm to synthetic data sets as well as process logs obtained from an IBM Flowmark installation.}},
    author = {Agrawal, Rakesh and Gunopulos, Dimitrios and Leymann, Frank},
    booktitle = {Advances in Database Technology — EDBT'98},
    chapter = {31},
    citeulike-article-id = {5044991},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/BFb0101003},
    citeulike-linkout-1 = {http://www.springerlink.com/content/0836165x01666l40},
    doi = {10.1007/BFb0101003},
    editor = {Schek, Hans-J\"{o}rg and Alonso, Gustavo and Saltor, Felix and Ramos, Isidro},
    isbn = {978-3-540-64264-0},
    journal = {Advances in Database Technology — EDBT'98},
    keywords = {q},
    pages = {467--483},
    posted-at = {2012-07-17 21:39:02},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Mining process models from workflow logs Advances in Database Technology — EDBT'98}},
    url = {http://dx.doi.org/10.1007/BFb0101003},
    volume = {1377},
    year = {1998}
}

@inproceedings{Shao2008Efficient,
    abstract = {{IT problem management calls for quick identification of resolvers to reported problems. The efficiency of this process highly depends on ticket routing---transferring problem ticket among various expert groups in search of the right resolver to the ticket. To achieve efficient ticket routing, wise decision needs to be made at each step of ticket transfer to determine which expert group is likely to be, or to lead to the resolver. In this paper, we address the possibility of improving ticket routing efficiency by mining ticket resolution sequences alone, without accessing ticket content. To demonstrate this possibility, a Markov model is developed to statistically capture the right decisions that have been made toward problem resolution, where the order of the Markov model is carefully chosen according to the conditional entropy obtained from ticket data. We also design a search algorithm, called Variable-order Multiple active State search(VMS), that generates ticket transfer recommendations based on our model. The proposed framework is evaluated on a large set of real-world problem tickets. The results demonstrate that VMS significantly improves human decisions: Problem resolvers can often be identified with fewer ticket transfers.}},
    address = {New York, NY, USA},
    author = {Shao, Qihong and Chen, Yi and Tao, Shu and Yan, Xifeng and Anerousis, Nikos},
    booktitle = {Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {6222090},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1401964},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1401890.1401964},
    doi = {10.1145/1401890.1401964},
    isbn = {978-1-60558-193-4},
    keywords = {data\_mining, q},
    location = {Las Vegas, Nevada, USA},
    pages = {605--613},
    posted-at = {2012-07-17 21:37:44},
    priority = {2},
    publisher = {ACM},
    series = {KDD '08},
    title = {{Efficient ticket routing by resolution sequence mining}},
    url = {http://dx.doi.org/10.1145/1401890.1401964},
    year = {2008}
}

@inproceedings{Cubranic2004Automatic,
    abstract = {{Bug triage, deciding what to do with an incoming bug report, is taking up increasing amount of developer resources in large open-source projects. In this paper, we propose to apply machine learning techniques to assist in bug triage by using text categorization to predict the developer that should work on the bug based on the bug\^{a}s description. We demonstrate our approach on a collection of 15,859 bug reports from a large open-source project. Our evaluation shows that our prototype, using supervised Bayesian learning, can correctly predict 30 \% of the report assignments to developers. 1}},
    author = {Cubranic, Davor and Murphy, Gail},
    booktitle = {In SEKE 2004: Proceedings of the Sixteenth International Conference on Software Engineering \& Knowledge Engineering},
    citeulike-article-id = {10896256},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.6144},
    keywords = {q},
    pages = {92--97},
    posted-at = {2012-07-17 21:35:49},
    priority = {2},
    title = {{Automatic bug triage using text categorization}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.6144},
    year = {2004}
}

@inproceedings{Canfora2006Supporting,
    abstract = {{Software repositories, such as CVS and Bugzilla, provide a huge amount of data regarding, respectively, source code and change request history. In this paper we propose a study on how change requests have been assigned to developers involved in an open source project and a method to suggest the set of best candidate developers to resolve a new change request. The method is based on the hypothesis that, given a new change request, developers that have resolved similar change requests in the past are the best candidates to resolve the new one. The suggestion can be useful for project managers in order to choose the best candidate to resolve a particular change request and/or to construct a competence database of developers working on software projects. We use the textual description of change requests stored in software repositories to index developers as documents in an information retrieval system. An Information Retrieval method is then applied to retrieve the candidate developers using the textual description of a new change request as a query.Case and evaluation study of the analysis and the methods introduced in this paper has been conducted on two large open source projects, Mozilla and KDE.}},
    address = {New York, NY, USA},
    author = {Canfora, Gerardo and Cerulo, Luigi},
    booktitle = {Proceedings of the 2006 ACM symposium on Applied computing},
    citeulike-article-id = {3347244},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1141277.1141693},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1141277.1141693},
    doi = {10.1145/1141277.1141693},
    isbn = {1-59593-108-2},
    keywords = {q},
    location = {Dijon, France},
    pages = {1767--1772},
    posted-at = {2012-07-17 21:34:09},
    priority = {2},
    publisher = {ACM},
    series = {SAC '06},
    title = {{Supporting change request assignment in open source development}},
    url = {http://dx.doi.org/10.1145/1141277.1141693},
    year = {2006}
}

@inproceedings{Bettenburg2008Duplicate,
    abstract = {{In a survey we found that most developers have experienced duplicated bug reports, however, only few considered them as a serious problem. This contradicts popular wisdom that considers bug duplicates as a serious problem for open source projects. In the survey, developers also pointed out that the additional information provided by duplicates helps to resolve bugs quicker. In this paper, we therefore propose to merge bug duplicates, rather than treating them separately. We quantify the amount of information that is added for developers and show that automatic triaging can be improved as well. In addition, we discuss the different reasons why users submit duplicate bug reports in the first place.}},
    author = {Bettenburg, Nicolas and Premraj, Rahul and Zimmermann, Thomas and Kim, Sunghun},
    booktitle = {2008 IEEE International Conference on Software Maintenance},
    citeulike-article-id = {10896251},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICSM.2008.4658082},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4658082},
    doi = {10.1109/ICSM.2008.4658082},
    isbn = {978-1-4244-2613-3},
    keywords = {bugs, q},
    location = {Beijing, China},
    pages = {337--345},
    posted-at = {2012-07-17 21:32:54},
    priority = {2},
    publisher = {IEEE},
    title = {{Duplicate bug reports considered harmful... really?}},
    url = {http://dx.doi.org/10.1109/ICSM.2008.4658082},
    year = {2008}
}

@inproceedings{Wang2008Approach,
    abstract = {{An open source project typically maintains an open bug repository so that bug reports from all over the world can be gathered. When a new bug report is submitted to the repository, a person, called a triager, examines whether it is a duplicate of an existing bug report. If it is, the triager marks it as DUPLICATE and the bug report is removed from consideration for further work. In the literature, there are approaches exploiting only natural language information to detect duplicate bug reports. In this paper we present a new approach that further involves execution information. In our approach, when a new bug report arrives, its natural language information and execution information are compared with those of the existing bug reports. Then, a small number of existing bug reports are suggested to the triager as the most similar bug reports to the new bug report. Finally, the triager examines the suggested bug reports to determine whether the new bug report duplicates an existing bug report. We calibrated our approach on a subset of the Eclipse bug repository and evaluated our approach on a subset of the Firefox bug repository. The experimental results show that our approach can detect 67\%-93\% of duplicate bug reports in the Firefox bug repository, compared to 43\%-72\% using natural language information alone.}},
    address = {New York, NY, USA},
    author = {Wang, Xiaoyin and Zhang, Lu and Xie, Tao and Anvik, John and Sun, Jiasu},
    booktitle = {Proceedings of the 30th international conference on Software engineering},
    citeulike-article-id = {8302848},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1368088.1368151},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1368088.1368151},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4814157},
    doi = {10.1145/1368088.1368151},
    isbn = {978-1-60558-079-1},
    keywords = {bugs, q},
    location = {Leipzig, Germany},
    pages = {461--470},
    posted-at = {2012-07-17 21:29:19},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '08},
    title = {{An approach to detecting duplicate bug reports using natural language and execution information}},
    url = {http://dx.doi.org/10.1145/1368088.1368151},
    year = {2008}
}

@inproceedings{Runeson2007Detection,
    abstract = {{Defect reports are generated from various testing and development activities in software engineering. Sometimes two reports are submitted that describe the same problem, leading to duplicate reports. These reports are mostly written in structured natural language, and as such, it is hard to compare two reports for similarity with formal methods. In order to identify duplicates, we investigate using natural language processing (NLP) techniques to support the identification. A prototype tool is developed and evaluated in a case study analyzing defect reports at Sony Ericsson mobile communications. The evaluation shows that about 2/3 of the duplicates can possibly be found using the NLP techniques. Different variants of the techniques provide only minor result differences, indicating a robust technology. User testing shows that the overall attitude towards the technique is positive and that it has a growth potential.}},
    address = {Washington, DC, USA},
    author = {Runeson, Per and Alexandersson, Magnus and Nyholm, Oskar},
    booktitle = {29th International Conference on Software Engineering (ICSE'07)},
    citeulike-article-id = {1727448},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1248882},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICSE.2007.32},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4222611},
    doi = {10.1109/ICSE.2007.32},
    institution = {Software Eng. Res. Group, Lund Univ., Lund},
    isbn = {0-7695-2828-7},
    issn = {0270-5257},
    keywords = {bugs, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {499--510},
    posted-at = {2012-07-17 21:27:43},
    priority = {2},
    publisher = {IEEE},
    series = {ICSE '07},
    title = {{Detection of Duplicate Defect Reports Using Natural Language Processing}},
    url = {http://dx.doi.org/10.1109/ICSE.2007.32},
    year = {2007}
}

@inproceedings{McDonald1998Just,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {McDonald, David W. and Ackerman, Mark S.},
    booktitle = {Proceedings of the 1998 ACM conference on Computer supported cooperative work},
    citeulike-article-id = {342891},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=289506},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/289444.289506},
    doi = {10.1145/289444.289506},
    isbn = {1-58113-009-0},
    keywords = {q},
    location = {Seattle, Washington, United States},
    pages = {315--324},
    posted-at = {2012-07-17 21:20:28},
    priority = {2},
    publisher = {ACM},
    series = {CSCW '98},
    title = {{Just talk to me: a field study of expertise location}},
    url = {http://dx.doi.org/10.1145/289444.289506},
    year = {1998}
}

@inproceedings{Herbsleb2001Empirical,
    abstract = {{Global software development is rapidly becoming the norm for technology companies. Previous qualitative research suggests that multi-site development may increase development cycle time. We use both survey data and data from the source code change management system to model the extent of delay in a multi-site software development organization, and explore several possible mechanisms for this delay. We also measure differences in same-site and cross-site communication patterns, and analyze the relationship of these variables to delay. Our results show that compared to same-site work, cross-site work takes much longer, and requires more people for work of equal size and complexity. We also report a strong relationship between delay in cross-site work and the degree to which remote colleagues are perceived to help out when workloads are heavy. We discuss implications of our findings for collaboration technology for distributed software development.}},
    address = {Washington, DC, USA},
    author = {Herbsleb, James D. and Mockus, Audris and Finholt, Thomas A. and Grinter, Rebecca E.},
    booktitle = {Proceedings of the 23rd International Conference on Software Engineering},
    citeulike-article-id = {203951},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=381481},
    isbn = {0-7695-1050-7},
    keywords = {q},
    location = {Toronto, Ontario, Canada},
    pages = {81--90},
    posted-at = {2012-07-17 21:19:40},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {ICSE '01},
    title = {{An empirical study of global software development: distance and speed}},
    url = {http://portal.acm.org/citation.cfm?id=381481},
    year = {2001}
}

@inproceedings{Bird2011Dont,
    abstract = {{Ownership is a key aspect of large-scale software development. We examine the relationship between different ownership measures and software failures in two large software projects: Windows Vista and Windows 7. We find that in all cases, measures of ownership such as the number of low-expertise developers, and the proportion of ownership for the top owner have a relationship with both pre-release faults and post-release failures. We also empirically identify reasons that low-expertise developers make changes to components and show that the removal of low-expertise contributions dramatically decreases the performance of contribution based defect prediction. Finally we provide recommendations for source code change policies and utilization of resources such as code inspections based on our results.}},
    address = {New York, NY, USA},
    author = {Bird, Christian and Nagappan, Nachiappan and Murphy, Brendan and Gall, Harald and Devanbu, Premkumar},
    booktitle = {Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering},
    citeulike-article-id = {9778579},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2025119},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2025113.2025119},
    doi = {10.1145/2025113.2025119},
    isbn = {978-1-4503-0443-6},
    keywords = {ownership, q},
    location = {Szeged, Hungary},
    pages = {4--14},
    posted-at = {2012-07-17 20:38:51},
    priority = {2},
    publisher = {ACM},
    series = {ESEC/FSE '11},
    title = {{Don't touch my code!: examining the effects of ownership on software quality}},
    url = {http://dx.doi.org/10.1145/2025113.2025119},
    year = {2011}
}

@inproceedings{Rahman2011Ownership,
    abstract = {{Recent research indicates that "people" factors such as ownership, experience, organizational structure, and geographic distribution have a big impact on software quality. Understanding these factors, and properly deploying people resources can help managers improve quality outcomes. This paper considers the impact of code ownership and developer experience on software quality. In a large project, a file might be entirely owned by a single developer, or worked on by many. Some previous research indicates that more developers working on a file might lead to more defects. Prior research considered this phenomenon at the level of modules or files, and thus does not tease apart and study the effect of contributions of different developers to each module or file. We exploit a modern version control system to examine this issue at a fine-grained level. Using version history, we examine contributions to code fragments that are actually repaired to fix bugs. Are these code fragments "implicated" in bugs the result of contributions from many? or from one? Does experience matter? What type of experience? We find that implicated code is more strongly associated with a single developer's contribution; our findings also indicate that an author's specialized experience in the target file is more important than general experience. Our findings suggest that quality control efforts could be profitably targeted at changes made by single developers with limited prior experience on that file.}},
    address = {New York, NY, USA},
    author = {Rahman, Foyzur and Devanbu, Premkumar},
    booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
    citeulike-article-id = {10896158},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1985860},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1985793.1985860},
    doi = {10.1145/1985793.1985860},
    isbn = {978-1-4503-0445-0},
    keywords = {expertise, ownership, q},
    location = {Waikiki, Honolulu, HI, USA},
    pages = {491--500},
    posted-at = {2012-07-17 20:37:20},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '11},
    title = {{Ownership, experience and defects: a fine-grained study of authorship}},
    url = {http://dx.doi.org/10.1145/1985793.1985860},
    year = {2011}
}

@article{Ko2006Exploratory,
    abstract = {{Much of software developers' time is spent understanding unfamiliar code. To better understand how developers gain this understanding and how software development environments might be involved, a study was performed in which developers were given an unfamiliar program and asked to work on two debugging tasks and three enhancement tasks for 70 minutes. The study found that developers interleaved three activities. They began by searching for relevant code both manually and using search tools; however, they based their searches on limited and misrepresentative cues in the code, environment, and executing program, often leading to failed searches. When developers found relevant code, they followed its incoming and outgoing dependencies, often returning to it and navigating its other dependencies; while doing so, however, Eclipse's navigational tools caused significant overhead. Developers collected code and other information that they believed would be necessary to edit, duplicate, or otherwise refer to later by encoding it in the interactive state of Eclipse's package explorer, file tabs, and scroll bars. However, developers lost track of relevant code as these interfaces were used for other tasks, and developers were forced to find it again. These issues caused developers to spend, on average, 35 percent of their time performing the mechanics of navigation within and between source files. These observations suggest a new model of program understanding grounded in theories of information foraging and suggest ideas for tools that help developers seek, relate, and collect information in a more effective and explicit manner.}},
    address = {Piscataway, NJ, USA},
    author = {Ko, Andrew J. and Myers, Brad A. and Coblenz, Michael J. and Aung, Htet H.},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {2057824},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1248780},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TSE.2006.116},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/TSE.2006.116},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4016573},
    doi = {10.1109/TSE.2006.116},
    issn = {0098-5589},
    journal = {IEEE Trans. Softw. Eng.},
    keywords = {code, developers, empirical, engineering, q, software, understanding},
    month = dec,
    number = {12},
    pages = {971--987},
    posted-at = {2012-07-03 23:03:22},
    priority = {2},
    publisher = {IEEE Press},
    title = {{An Exploratory Study of How Developers Seek, Relate, and Collect Relevant Information during Software Maintenance Tasks}},
    url = {http://dx.doi.org/10.1109/TSE.2006.116},
    volume = {32},
    year = {2006}
}

@article{Kagdi2012Assigning,
    abstract = {{The paper presents an approach to recommend a ranked list of expert developers to assist in the implementation of software change requests (e.g., bug reports and feature requests). An Information Retrieval (IR)-based concept location technique is first used to locate source code entities, e.g., files and classes, relevant to a given textual description of a change request. The previous commits from version control repositories of these entities are then mined for expert developers. The role of the IR method in selectively reducing the mining space is different from previous approaches that textually index past change requests and/or commits. The approach is evaluated on change requests from three open-source systems: ArgoUML, Eclipse, and KOffice, across a range of accuracy criteria. The results show that the overall accuracies of the correctly recommended developers are between 47 and 96\% for bug reports, and between 43 and 60\% for feature requests. Moreover, comparison results with two other recommendation alternatives show that the presented approach outperforms them with a substantial margin. Project leads or developers can use this approach in maintenance tasks immediately after the receipt of a change request in a free-form text. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.}},
    author = {Kagdi, Huzefa and Gethers, Malcom and Poshyvanyk, Denys and Hammad, Maen},
    citeulike-article-id = {10854078},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/smr.530},
    doi = {10.1002/smr.530},
    journal = {J. Softw. Evol. and Proc.},
    keywords = {q},
    number = {1},
    pages = {3--33},
    posted-at = {2012-07-03 22:57:31},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd},
    title = {{Assigning change requests to software developers}},
    url = {http://dx.doi.org/10.1002/smr.530},
    volume = {24},
    year = {2012}
}

@inproceedings{Kagdi2009Who,
    abstract = {{An approach to recommend a ranked list of developers to assist in performing software changes given a textual change request is presented. The approach employs a two-fold strategy. First, a technique based on information retrieval is put at work to locate the relevant units of source code, e.g., files, classes, and methods, to a given change request. These units of source code are then fed to a technique that recommends developers based on their source code change expertise, experience, and contributions, as derived from the analysis of the previous commits. The commits are obtained from a software system's version control repositories (e.g., Subversion). The approach is demonstrated on a bug report from KOffice, an open source application suite.}},
    author = {Kagdi, Huzefa and Poshyvanyk, Denys},
    booktitle = {2009 IEEE 17th International Conference on Program Comprehension},
    citeulike-article-id = {9783605},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICPC.2009.5090056},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5090056},
    doi = {10.1109/ICPC.2009.5090056},
    isbn = {978-1-4244-3998-0},
    issn = {1063-6897},
    keywords = {q},
    location = {Vancouver, BC, Canada},
    month = may,
    pages = {273--277},
    posted-at = {2012-07-03 22:56:09},
    priority = {2},
    publisher = {IEEE},
    title = {{Who can help me with this change request?}},
    url = {http://dx.doi.org/10.1109/ICPC.2009.5090056},
    year = {2009}
}

@article{Kagdi2007Survey,
    abstract = {{A comprehensive literature survey on approaches for mining software repositories (MSR) in the context of software evolution is presented. In particular, this survey deals with those investigations that examine multiple versions of software artifacts or other temporal information. A taxonomy is derived from the analysis of this literature and presents the work via four dimensions: the type of software repositories mined (what), the purpose (why), the adopted/invented methodology used (how), and the evaluation method (quality). The taxonomy is demonstrated to be expressive (i.e., capable of representing a wide spectrum of MSR investigations) and effective (i.e., facilitates similarities and comparisons of MSR investigations). Lastly, a number of open research issues in MSR that require further investigation are identified.}},
    address = {New York, NY, USA},
    author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
    citeulike-article-id = {4534888},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1345056.1345057},
    citeulike-linkout-1 = {http://dx.doi.org/10.1002/smr.344},
    doi = {10.1002/smr.344},
    issn = {1532-060X},
    journal = {J. Softw. Maint. Evol.},
    keywords = {q},
    month = mar,
    number = {2},
    pages = {77--131},
    posted-at = {2012-07-03 22:48:38},
    priority = {2},
    publisher = {John Wiley \&amp; Sons, Inc.},
    title = {{A survey and taxonomy of approaches for mining software repositories in the context of software evolution}},
    url = {http://dx.doi.org/10.1002/smr.344},
    volume = {19},
    year = {2007}
}

@article{Zimmermann2005Mining,
    abstract = {{We apply data mining to version histories in order to guide programmers along related changes: "Programmers who changed these functions also changed...." Given a set of existing changes, the mined association rules 1) suggest and predict likely further changes, 2) show up item coupling that is undetectable by program analysis, and 3) can prevent errors due to incomplete changes. After an initial change, our ROSE prototype can correctly predict further locations to be changed; the best predictive power is obtained for changes to existing software. In our evaluation based on the history of eight popular open source projects, ROSE's topmost three suggestions contained a correct location with a likelihood of more than 70 percent.}},
    address = {Los Alamitos, CA, USA},
    author = {Zimmermann, T. and Zeller, A. and Weissgerber, P. and Diehl, S.},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {277045},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TSE.2005.72},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/TSE.2005.72},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1463228},
    day = {11},
    doi = {10.1109/TSE.2005.72},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    keywords = {q},
    month = jun,
    number = {6},
    pages = {429--445},
    posted-at = {2012-07-03 22:47:59},
    priority = {2},
    publisher = {IEEE},
    title = {{Mining version histories to guide software changes}},
    url = {http://dx.doi.org/10.1109/TSE.2005.72},
    volume = {31},
    year = {2005}
}

@inproceedings{Ma2009Expert,
    abstract = {{Global and distributed software development increases the need to find and connect developers with relevant expertise. Existing recommendation systems typically model expertise based on file changes (implementation expertise). While these approaches have shown success, they require a substantial recorded history of development for a project. Previously, we have proposed the concept of usage expertise, i.e., expertise manifested through the act of calling (using) a method. In this paper, we assess the viability of this concept by evaluating expert recommendations for the ASPECTJ and ECLIPSE projects. We find that both usage and implementation expertise have comparable levels of accuracy, which suggests that usage expertise may be used as a substitute measure. We also find a notable overlap of method calls across both projects, which suggests that usage expertise can be leveraged to recommend experts from different projects and thus for projects with little or no history.}},
    address = {Los Alamitos, CA, USA},
    author = {Ma, David and Schuler, David and Zimmermann, Thomas and Sillito, Jonathan},
    booktitle = {2009 IEEE International Conference on Software Maintenance},
    citeulike-article-id = {7553504},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2009.5306386},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICSM.2009.5306386},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5306386},
    doi = {10.1109/ICSM.2009.5306386},
    isbn = {978-1-4244-4897-5},
    journal = {Software Maintenance, IEEE International Conference on},
    keywords = {q},
    location = {Edmonton, AB, Canada},
    month = sep,
    pages = {535--538},
    posted-at = {2012-07-03 22:44:32},
    priority = {2},
    publisher = {IEEE},
    title = {{Expert recommendation with usage expertise}},
    url = {http://dx.doi.org/10.1109/ICSM.2009.5306386},
    volume = {0},
    year = {2009}
}

@inproceedings{Anvik2006Who,
    abstract = {{Open source development projects typically support an open bug repository to which both developers and users can report bugs. The reports that appear in this repository must be triaged to determine if the report is one which requires attention and if it is, which developer will be assigned the responsibility of resolving the report. Large open source developments are burdened by the rate at which new bug reports appear in the bug repository. In this paper, we present a semi-automated approach intended to ease one part of this process, the assignment of reports to a developer. Our approach applies a machine learning algorithm to the open bug repository to learn the kinds of reports each developer resolves. When a new report arrives, the classifier produced by the machine learning technique suggests a small number of developers suitable to resolve the report. With this approach, we have reached precision levels of 57\% and 64\% on the Eclipse and Firefox development projects respectively. We have also applied our approach to the gcc open source development with less positive results. We describe the conditions under which the approach is applicable and also report on the lessons we learned about applying machine learning to repositories used in open source development.}},
    address = {New York, NY, USA},
    author = {Anvik, John and Hiew, Lyndon and Murphy, Gail C.},
    booktitle = {Proceedings of the 28th international conference on Software engineering},
    citeulike-article-id = {682724},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134285.1134336},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1134285.1134336},
    doi = {10.1145/1134285.1134336},
    isbn = {1-59593-375-1},
    keywords = {q},
    location = {Shanghai, China},
    pages = {361--370},
    posted-at = {2012-07-03 22:34:32},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '06},
    title = {{Who should fix this bug?}},
    url = {http://dx.doi.org/10.1145/1134285.1134336},
    year = {2006}
}

@article{German2006Empirical,
    abstract = {{Software is typically improved and modified in small increments (we refer to each of these increments as a modification record—MR). MRs are usually stored in a configuration management or version control system and can be retrieved for analysis. In this study we retrieved the MRs from several mature open software projects. We then concentrated our analysis on those MRs that fix defects and provided heuristics to automatically classify them. We used the information in the MRs to visualize what files are changed at the same time, and who are the people who tend to modify certain files. We argue that these visualizations can be used to understand the development stage of in which a project is at a given time (new features are added, or defects are being fixed), the level of modularization of a project, and how developers might interact between each other and the source code of a system.}},
    address = {Hingham, MA, USA},
    author = {German, Daniel M.},
    citeulike-article-id = {5014724},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1146486},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10664-006-9004-6},
    citeulike-linkout-2 = {http://www.springerlink.com/content/h20184118g77227r},
    day = {1},
    doi = {10.1007/s10664-006-9004-6},
    issn = {1382-3256},
    journal = {Empirical Software Engineering},
    keywords = {msr, q},
    month = sep,
    number = {3},
    pages = {369--393},
    posted-at = {2012-06-18 03:19:14},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {{An empirical study of fine-grained software modifications}},
    url = {http://dx.doi.org/10.1007/s10664-006-9004-6},
    volume = {11},
    year = {2006}
}

@inproceedings{Weissgerber2007Visual,
    abstract = {{Analyzing the check-in information of open source software projects which use a version control system such as CVS or SUBVERSION can yield interesting and important insights into the programming behavior of developers. As in every major project tasks are assigned to many developers, the development must be coordinated between these programmers. This paper describes three visualization techniques that help to examine how programmers work together, e.g. if they work as a team or if they develop their part of the software separate from each other. Furthermore, phases of stagnation in the lifetime of a project can be uncovered and thus, possible problems are revealed. To demonstrate the usefulness of these visualization techniques we performed case studies on two open source projects. In these studies interesting patterns of developers' behavior, e.g. the specialization on a certain module can be observed. Moreover, modules that have been changed by many developers can be identified as well as such ones that have been altered by only one programmer.}},
    author = {Weissgerber, Peter and Pohl, Mathias and Burch, Michael},
    booktitle = {Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)},
    citeulike-article-id = {10799268},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MSR.2007.34},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228646},
    doi = {10.1109/MSR.2007.34},
    isbn = {0-7695-2950-X},
    keywords = {expertise, msr, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {9},
    posted-at = {2012-06-18 03:14:53},
    priority = {2},
    publisher = {IEEE},
    title = {{Visual Data Mining in Software Archives to Detect How Developers Work Together}},
    url = {http://dx.doi.org/10.1109/MSR.2007.34},
    year = {2007}
}

@inproceedings{Yu2007Mining,
    abstract = {{This paper presents a model to represent the interactions of distributed open-source software developers and utilizes data mining techniques to derive developer roles. The model is then applied on case studies of two open-source projects, ORAC-DR and Mediawiki with encouraging results.}},
    author = {Yu, Liguo and Ramaswamy, Srini},
    booktitle = {Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)},
    citeulike-article-id = {10799265},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MSR.2007.19},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228645},
    doi = {10.1109/MSR.2007.19},
    isbn = {0-7695-2950-X},
    keywords = {expertise, msr, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {8},
    posted-at = {2012-06-18 03:14:04},
    priority = {2},
    publisher = {IEEE},
    title = {{Mining CVS Repositories to Understand Open-Source Project Developer Roles}},
    url = {http://dx.doi.org/10.1109/MSR.2007.19},
    year = {2007}
}

@inproceedings{Schuler2008Mining,
    abstract = {{In software development, there is an increasing need to find and connect developers with relevant expertise. Existing expertise recommendation systems are mostly based on variations of the Line 10 Rule: developers who changed a file most often have the most implementation expertise. In this paper, we introduce the concept of usage expertise, which manifests itself whenever developers are using functionality, e.g., by calling API methods. We present preliminary results for the ECLIPSE project that demonstrate that our technique allows to recommend experts for files with no or little history, identify developers with similar expertise, and measure the usage of API methods.}},
    address = {New York, NY, USA},
    author = {Schuler, David and Zimmermann, Thomas},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {6662019},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370779},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370779},
    doi = {10.1145/1370750.1370779},
    isbn = {978-1-60558-024-1},
    keywords = {expertise, q},
    location = {Leipzig, Germany},
    pages = {121--124},
    posted-at = {2012-06-18 03:10:11},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{Mining usage expertise from version archives}},
    url = {http://dx.doi.org/10.1145/1370750.1370779},
    year = {2008}
}

@article{DelRosso2009Comprehend,
    abstract = {{When a set of people are connected by a set of meaningful social relationships we talk of a social network. A social network represents a social structure and the underlying structural patterns can be used to analyze and comprehend how people relate to each other and their emergent behavior as a group. Developing software is fundamentally a human activity. Developers cooperate and exchange knowledge and information, creating in fact, a particular type of social network that we call knowledge network. In this paper we investigate knowledge networks in software development teams by applying social network analysis and we use the Apache web server as a case study. By analyzing the structural communication and coordination patterns in Apache we have been able to identify the Apache knowledge network, highlight potential communication bottlenecks, and find brokers and important coordination points in the software development team. Furthermore, our work enables a software architect to analyze and maintain the organization and the software architecture aligned during software evolution. An important lesson that we have is that the analysis of knowledge networks constitutes an additional tool to be added to the traditional software architecture assessment methods. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.}},
    author = {Del Rosso, Christian},
    citeulike-article-id = {10799238},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/smr.408},
    doi = {10.1002/smr.408},
    journal = {J. Softw. Maint. Evol.: Res. Pract.},
    keywords = {q, social},
    number = {3},
    pages = {189--215},
    posted-at = {2012-06-18 03:08:33},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {{Comprehend and analyze knowledge networks to improve software evolution}},
    url = {http://dx.doi.org/10.1002/smr.408},
    volume = {21},
    year = {2009}
}

@inproceedings{Bird2006Mining,
    abstract = {{Communication \& Co-ordination activities are central to large software projects, but are difficult to observe and study in traditional (closed-source, commercial) settings because of the prevalence of informal, direct communication modes. OSS projects, on the other hand, use the internet as the communication medium,and typically conduct discussions in an open, public manner. As a result, the email archives of OSS projects provide a useful trace of the communication and co-ordination activities of the participants. However, there are various challenges that must be addressed before this data can be effectively mined. Once this is done, we can construct social networks of email correspondents, and begin to address some interesting questions. These include questions relating to participation in the email; the social status of different types of OSS participants; the relationship of email activity and commit activity (in the CVS repositories) and the relationship of social status with commit activity. In this paper, we begin with a discussion of our infrastructure (including a novel use of Scientific Workflow software) and then discuss our approach to mining the email archives; and finally we present some preliminary results from our data analysis.}},
    address = {New York, NY, USA},
    author = {Bird, Christian and Gourley, Alex and Devanbu, Prem and Gertz, Michael and Swaminathan, Anand},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {1240643},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1138016},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138016},
    doi = {10.1145/1137983.1138016},
    isbn = {1-59593-397-2},
    keywords = {email, msr, q},
    location = {Shanghai, China},
    pages = {137--143},
    posted-at = {2012-06-18 03:06:15},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {{Mining email social networks}},
    url = {http://dx.doi.org/10.1145/1137983.1138016},
    year = {2006}
}

@inproceedings{German2006Study,
    abstract = {{This report describes some characteristics of the development team of PostgreSQL that were uncovered by analyzing the history of its software artifacts as recorded by the project's CVS repository.}},
    address = {New York, NY, USA},
    author = {German, Daniel M.},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {10799193},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1138022},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138022},
    doi = {10.1145/1137983.1138022},
    isbn = {1-59593-397-2},
    keywords = {expertise, msr, q},
    location = {Shanghai, China},
    pages = {163--164},
    posted-at = {2012-06-18 03:01:49},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {{A study of the contributors of PostgreSQL}},
    url = {http://dx.doi.org/10.1145/1137983.1138022},
    year = {2006}
}

@inproceedings{Matter2009Assigning,
    abstract = {{For popular software systems, the number of daily submitted bug reports is high. Triaging these incoming reports is a time consuming task. Part of the bug triage is the assignment of a report to a developer with the appropriate expertise. In this paper, we present an approach to automatically suggest developers who have the appropriate expertise for handling a bug report. We model developer expertise using the vocabulary found in their source code contributions and compare this vocabulary to the vocabulary of bug reports. We evaluate our approach by comparing the suggested experts to the persons who eventually worked on the bug. Using eight years of Eclipse development as a case study, we achieve 33.6\% top-1 precision and 71.0\% top-10 recall.}},
    address = {Washington, DC, USA},
    author = {Matter, Dominique and Kuhn, Adrian and Nierstrasz, Oscar},
    booktitle = {2009 6th IEEE International Working Conference on Mining Software Repositories},
    citeulike-article-id = {5047743},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1590955.1591148},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2009.5069491},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5069491},
    doi = {10.1109/MSR.2009.5069491},
    isbn = {978-1-4244-3493-0},
    journal = {Mining Software Repositories, 2009. MSR '09. 6th IEEE International Working Conference on},
    keywords = {bugs, expertise, q},
    location = {Vancouver, BC, Canada},
    month = may,
    pages = {131--140},
    posted-at = {2012-06-18 03:00:54},
    priority = {2},
    publisher = {IEEE},
    title = {{Assigning bug reports using a vocabulary-based expertise model of developers}},
    url = {http://dx.doi.org/10.1109/MSR.2009.5069491},
    year = {2009}
}

@inproceedings{Jeong2009Improving,
    abstract = {{bug report is typically assigned to a single developer who is then responsible for fixing the bug. In Mozilla and Eclipse, between 37\%-44\% of bug reports are "tossed" (reassigned) to other developers, for example because the bug has been assigned by accident or another developer with additional expertise is needed. In any case, tossing increases the time-to-correction for a bug. In this paper, we introduce a graph model based on Markov chains, which captures bug tossing history. This model has several desirable qualities. First, it reveals developer networks which can be used to discover team structures and to find suitable experts for a new task. Second, it helps to better assign developers to bug reports. In our experiments with 445,000 bug reports, our model reduced tossing events, by up to 72\%. In addition, the model increased the prediction accuracy by up to 23 percentage points compared to traditional bug triaging approaches.}},
    address = {New York, NY, USA},
    author = {Jeong, Gaeul and Kim, Sunghun and Zimmermann, Thomas},
    booktitle = {Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
    citeulike-article-id = {6066150},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1595715},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1595696.1595715},
    doi = {10.1145/1595696.1595715},
    isbn = {978-1-60558-001-2},
    keywords = {bugs, expertise, q},
    location = {Amsterdam, The Netherlands},
    pages = {111--120},
    posted-at = {2012-06-18 02:59:13},
    priority = {2},
    publisher = {ACM},
    series = {ESEC/FSE '09},
    title = {{Improving bug triage with bug tossing graphs}},
    url = {http://dx.doi.org/10.1145/1595696.1595715},
    year = {2009}
}

@incollection{Song2005ExpertiseNet,
    abstract = {{We develop a novel user-centric modeling technology, which can dynamically describe and update a person's expertise profile. In an enterprise environment, the technology can enhance employees' collaboration and productivity by assisting in finding experts, training employees, etc. Instead of using the traditional search methods, such as the keyword match, we propose to use relational and evolutionary graph models, which we call ExpertiseNet, to describe and find experts. These ExpertiseNets are used for mining, retrieval, and visualization. We conduct experiments by building ExpertiseNets for researchers from a research paper collection. The experiments demonstrate that expertise mining and matching are more efficiently achieved based on the proposed relational and evolutionary graph models.}},
    address = {Berlin, Heidelberg},
    author = {Song, Xiaodan and Tseng, Belle L. and Lin, Ching-Yung and Sun, Ming-Ting},
    chapter = {14},
    citeulike-article-id = {781068},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11527886\_14},
    citeulike-linkout-1 = {http://www.springerlink.com/content/3tu0amrppe9nw959},
    doi = {10.1007/11527886\_14},
    editor = {Ardissono, Liliana and Brna, Paul and Mitrovic, Antonija},
    isbn = {978-3-540-27885-6},
    journal = {Lecture Notes in Computer Science},
    keywords = {expertise, q},
    pages = {150},
    posted-at = {2012-06-18 02:58:01},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{ExpertiseNet: Relational and Evolutionary Expert Modeling User Modeling 2005}},
    url = {http://dx.doi.org/10.1007/11527886\_14},
    volume = {3538},
    year = {2005}
}

@inproceedings{Anvik2007Determining,
    abstract = {{As developers work on a software product they accumulate expertise, including expertise about the code base of the software product. We call this type of expertise 'implementation expertise'. Knowing the set of developers who have implementation expertise for a software product has many important uses. This paper presents an empirical evaluation of two approaches to determining implementation expertise from the data in source and bug repositories. The expertise sets created by the approaches are compared to those provided by experts and evaluated using the measures of precision and recall. We found that both approaches are good at finding all of the appropriate developers, although they vary in how many false positives are returned.}},
    address = {Washington, DC, USA},
    author = {Anvik, John and Murphy, Gail C.},
    booktitle = {Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)},
    citeulike-article-id = {3064726},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1268983.1269018},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2007.7},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228639},
    doi = {10.1109/MSR.2007.7},
    isbn = {0-7695-2950-X},
    journal = {Mining Software Repositories, 2007. ICSE Workshops MSR '07. Fourth International Workshop on},
    keywords = {bugs, expertise, msr, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {2},
    posted-at = {2012-06-18 02:57:18},
    priority = {2},
    publisher = {IEEE},
    title = {{Determining Implementation Expertise from Bug Reports}},
    url = {http://dx.doi.org/10.1109/MSR.2007.7},
    year = {2007}
}

@inproceedings{Mockus2002Expertise,
    abstract = {{Finding relevant expertise is a critical need in collaborative software engineering, particularly in geographically distributed developments. We introduce a tool that uses data from change management systems to locate people with desired expertise. It uses a quantification of experience, and presents evidence to validate this quantification as a measure of expertise. The tool enables developers, for example, easily to distinguish someone who has worked only briefly in a particular area of the code from someone who has more extensive experience, and to locate people with broad expertise throughout large parts of the product, such as module or even subsystems. In addition, it allows a user to discover expertise profiles for individuals or organizations. Data from a deployment of the tool in a large software development organization shows that newer, remote sites tend to use the tool for expertise location more frequently. Larger, more established sites used the tool to find expertise profiles for people or organizations. We conclude by describing extensions that provide continuous awareness of ongoing work and an interactive, quantitative resume.}},
    address = {New York, NY, USA},
    author = {Mockus, Audris and Herbsleb, James D.},
    booktitle = {Proceedings of the 24th International Conference on Software Engineering},
    citeulike-article-id = {4733461},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=581401},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/581339.581401},
    doi = {10.1145/581339.581401},
    isbn = {1-58113-472-X},
    keywords = {expertise, q},
    location = {Orlando, Florida},
    pages = {503--512},
    posted-at = {2012-06-18 02:54:51},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '02},
    title = {{Expertise browser: a quantitative approach to identifying expertise}},
    url = {http://dx.doi.org/10.1145/581339.581401},
    year = {2002}
}

@inproceedings{Cataldo2006Identification,
    abstract = {{Task dependencies drive the need to coordinate work activities. We describe a technique for using automatically generated archi-val data to compute coordination requirements, i.e., who must coordinate with whom to get the work done. Analysis of data from a large software development project revealed that coordina-tion requirements were highly volatile, and frequently extended beyond team boundaries. Congruence between coordination re-quirements and coordination activities shortened development time. Developers, particularly the most productive ones, changed their use of electronic communication media over time, achieving higher congruence. We discuss practical implications of our technique for the design of collaborative and awareness tools.}},
    address = {New York, NY, USA},
    author = {Cataldo, Marcelo and Wagstrom, Patrick A. and Herbsleb, James D. and Carley, Kathleen M.},
    booktitle = {Proceedings of the 2006 20th anniversary conference on Computer supported cooperative work},
    citeulike-article-id = {1022639},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1180875.1180929},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1180875.1180929},
    doi = {10.1145/1180875.1180929},
    isbn = {1-59593-249-6},
    keywords = {q},
    location = {Banff, Alberta, Canada},
    pages = {353--362},
    posted-at = {2012-06-18 02:54:03},
    priority = {2},
    publisher = {ACM},
    series = {CSCW '06},
    title = {{Identification of coordination requirements: implications for the Design of collaboration and awareness tools}},
    url = {http://dx.doi.org/10.1145/1180875.1180929},
    year = {2006}
}

@inproceedings{Minto2007Recommending,
    abstract = {{To build successful complex software systems, developers must collaborate with each other to solve issues. To facilitate this collaboration, specialized tools, such as chat and screen sharing, are being integrated into development environments. Currently, these tools require a developer to maintain a list of other developers with whom they may wish to communicate and to determine who within this list has expertise for a specific situation. For large, dynamic projects, like several successful open-source projects, these requirements place an unreasonable burden on the developer. In this paper, we show how the structure of a team emerges from how developers change software artifacts. We introduce the emergent expertise locator (EEL) that uses emergent team information to propose experts to a developer within their development environment as the developer works. We found that EEL produces, on average, results with higher precision and higher recall than an existing heuristic for expertise recommendation.}},
    address = {Washington, DC, USA},
    author = {Minto, Shawn and Murphy, Gail C.},
    booktitle = {Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)},
    citeulike-article-id = {1680925},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1269021},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2007.27},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228642},
    doi = {10.1109/MSR.2007.27},
    isbn = {0-7695-2950-X},
    journal = {Mining Software Repositories, 2007. ICSE Workshops MSR '07. Fourth International Workshop on},
    keywords = {expertise, mining, q},
    location = {Minneapolis, MN, USA},
    month = may,
    pages = {5},
    posted-at = {2012-06-18 02:48:11},
    priority = {2},
    publisher = {IEEE},
    title = {{Recommending Emergent Teams}},
    url = {http://dx.doi.org/10.1109/MSR.2007.27},
    year = {2007}
}

@inproceedings{McDonald2000Expertise,
    abstract = {{Locating the expertise necessary to solve difficult problems is a nuanced social and collaborative problem. In organizations, some people assist others in locating expertise by making referrals. People who make referrals fill key organizational roles that have been identified by CSCW and affiliated research. Expertise locating systems are not designed to replace people who fill these key organizational roles. Instead, expertise locating systems attempt to decrease workload and support people who have no other options. Recommendation systems are collaborative software that can be applied to expertise locating. This work describes a general recommendation architecture that is grounded in a field study of expertise locating. Our expertise recommendation system details the work necessary to fit expertise recommendation to a work setting. The architecture and implementation begin to tease apart the technical aspects of providing good recommendations from social and collaborative concerns.}},
    address = {New York, NY, USA},
    author = {McDonald, David W. and Ackerman, Mark S.},
    booktitle = {Proceedings of the 2000 ACM conference on Computer supported cooperative work},
    citeulike-article-id = {1159},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=358994},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/358916.358994},
    doi = {10.1145/358916.358994},
    isbn = {1-58113-222-0},
    keywords = {expertise, ownership, q},
    location = {Philadelphia, Pennsylvania, United States},
    pages = {231--240},
    posted-at = {2012-06-18 02:47:20},
    priority = {2},
    publisher = {ACM},
    series = {CSCW '00},
    title = {{Expertise recommender: a flexible recommendation system and architecture}},
    url = {http://dx.doi.org/10.1145/358916.358994},
    year = {2000}
}

@inproceedings{Kagdi2008Who,
    abstract = {{An approach to recommend a ranked list of developers to assist in performing software changes to a particular file is presented. The ranking is based on change expertise, experience, and contributions of developers, as derived from the analysis of the previous commits involving the specific file in question. The commits are obtained from a software systempsilas version control repositories (e.g., Subversion). The basic premise is that a developer who has substantially contributed changes to specific files in the past is likely to best assist for their current or future change. Evaluation of the approach on a number of open source systems such as koffice, Apache httpd, and GNU gcc is also presented. The results show that the accuracy of the correctly recommended developers is between 43\% and 82\%. New developers to a long-lived software project, or project managers, can use this approach to assist them in undertaking maintenance tasks, e.g., bug fix or adding a new feature. The approach can be realized as a plug-in to development environments such as Eclipse.}},
    author = {Kagdi, Huzefa and Hammad, Maen and Maletic, Jonathan I.},
    booktitle = {2008 IEEE International Conference on Software Maintenance},
    citeulike-article-id = {6066163},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ICSM.2008.4658064},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4658064},
    day = {24},
    doi = {10.1109/ICSM.2008.4658064},
    isbn = {978-1-4244-2613-3},
    issn = {1063-6773},
    journal = {Software Maintenance, 2008. ICSM 2008. IEEE International Conference on},
    keywords = {ownership, q},
    location = {Beijing, China},
    month = sep,
    pages = {157--166},
    posted-at = {2012-06-18 02:21:13},
    priority = {3},
    publisher = {IEEE},
    title = {{Who can help me with this source code change?}},
    url = {http://dx.doi.org/10.1109/ICSM.2008.4658064},
    year = {2008}
}

--Books

@book{Henderson-Sellers:1996,
   author      = {B. {Henderson-Sellers}},
   title       = {Object-Oriented Metrics: Measures of Complexity},
   year        = 1996,
   publisher   = {Prentice Hall}
}

--Misc

@misc{Basili-etal:1994
, author       = {V. Basili and G. Caldiera and H.D. Rombach}
, title        = {The Goal Question Metric Approach}
, year         = 1994
, url          = {ftp://ftp.cs.umd.edu/pub/sel/papers/gqm.pdf}
}

--Articles

@article{Bird-etal:2010,
   author   = {C. Bird and N. Nagappan and B. Murphy and H. Gall and P. Devanbu},
   title    = {An Analysis of the Effect of Code Ownership on Software Quality across {Windows}, {Eclipse}, and {Firefox}},
   year     = 2010,
}

@article{Blei-etal:2003
, author       = {D.M. Blei and A.Y. Ng and M.I. Jordan}
, title        = {Latent {D}irichlet Allocation}
, journal      = {J. of Machine Learning Research}
, volume       = 3
, year         = 2003
, pages        = {993--1022}
}

@article{Chang-Blei:2010
, author       = {J. Chang and D.M. Blei}
, title        = {Hierarchical relational models for document networks}
, journal      = {Annals of Appl. Stats}
, volume       = 4
, number       = 1
, year         = 2010
, pages        = {124--150}
}

@article{Chidamber-Kemerer:1994,
   author   = {S.R. Chidamber and C.F. Kemerer},
   title    = {A metrics suite for object oriented design},
   journal  = {IEEE Transactions on Software Engineering},
   year     = 1994,
   volume   = 20,
   number   = 6,
   pages    = {476--493},
}

@article{Corbi:1989,
   author   = {T.A. Corbi},
   title    = {Program understanding: challenge for the 1990's},
   journal  = {IBM Syst. J.},
   volume   = 28,
   number   = 2,
   year     = 1989,
   pages    = {294--306}
}

@article{FongBoh-etal:2007,
	Author   = {Fong Boh, W. and Slaughter, S.A. and Espinosa, J.A.},
	Title    = {Learning from Experience in Software Development: A Multilevel Analysis},
	Journal  = {Management Science},
	Volume   = {53},
	Number   = {8},
	Year     = {2007},
	Month    = {August},
	Pages    = {1315--1331},
}

@article{Graves-etal:2000,
   author   = {T.L. Graves and A.F. Karr and J.S. Marron and H. Siy},
   title    = {Predicting Fault Incidence Using Software Change History},
   journal  = {IEEE Transactions on Software Engineering},
   volume   = 26,
   number   = 7,
   year     = 2000,
   month    = jul,
   pages    = {653--661},
}

@article{Griffiths-Steyvers:2004
, author       = {T.L. Griffiths and M. Steyvers}
, title        = {Finding Scientific Topics}
, journal      = {Proc. of the Natl. Academy of Sciences}
, year         = 2004
, volume       = 101
, number       = {Suppl. 1}
, pages        = {5228--5235}
, doi          = {10.1073/pnas.0307752101}
}

@article{Kagdi-etal:2011,
   author      = {H. Kagdi and M. Gethers and D. Poshyvanyk and M. Hammad},
   title       = {Assigning change requests to software developers},
   journal     = {Journal of Software Maintenance and Evolution: Research and Practice},
   year        = 2011,
}

@article{Kuhn-etal:2007,
   author   = {A. Kuhn and S. Ducasse and T. Girba},
   title    = {Semantic clustering: Identifying topics in source code},
   journal  = {Information and Software Technology},
   year     = 2007,
   volume   = 49,
   number   = 2007,
   pages    = {230--243}
}

@article{Lukins-etal:2010
, author       = {S.K. Lukins and N.A. Kraft and L.H. Etzkorn}
, title        = {Bug Localization using Latent {D}irichlet Allocation}
, journal      = {Information and Software Technology}
, year         = 2010 
, volume       = 52 
, number       = 9  
, pages        = {972--990}
, month        = sep
, publisher    = {Elsevier}
}

@article{Mockus-Weiss:2000,
   author   = {A. Mockus and D. Weiss},
   title    = {Predicting risk of software changes},
   journal  = {Bell Labs Technical Journal},
   year     = 2000,
   volume   = 5,
   number   = 2,
   pages    = {169--180}
}

@article{Ostrand-etal:2005,
   author   = {T.J. Ostrand and E.J. Weyuker and R.M. Bell},
   title    = {Predicting the Location and Number of Faults in Large Software Systems},
   journal  = {IEEE Transactions on Software Engineering},
   volume   = 31,
   number   = 4,
   year     = 2005,
   month    = apr,
   pages    = {340--355},
}

@article{Robillard:1999,
	Author   = {Robillard, P.N.},
	Title    = {The role of knowledge in software development},
	Journal  = {Commun. ACM},
	Volume   = {42},
	Issue    = {1},
	Year     = {1999},
	Month    = {January},
	Pages    = {87--92},
}

--InProceedings

@article{Andrieu-etal:2003
, author       = {C. Andrieu and N.D. Freitas and A. Doucet and M. Jordan}
, title        = {An introduction to MCMC for machine learning}
, journal      = {Machine Learning}
, volume       = 50
, number       = {1--2}
, year         = 2003
, pages        = {5--43}
}

@inproceedings{Asuncion-etal:2010
, author       = {H. Asuncion and A. Asuncion and R. Taylor}
, title        = {Software Traceability with Topic Modeling}
, booktitle    = {Proc. of the 32nd Int'l Conf. on Software Engineering}
, year         = 2010
, pages        = {95--104}
}

@inproceedings{Baldi-etal:2008
, author       = {P. Baldi and E. Linstead and C. Lopes and S. Bajracharya}
, title        = {A Theory of Aspects as Latent Topics}
, booktitle    = {Proc. of the ACM SIGPLAN Conf. on Object-Oriented Programming, Systems, Languages, and Applications}
, year         = 2008
, pages        = {543--562}
}

@inproceedings{Bird-etal:2006,
   author      = {C. Bird and A. Gourley and P. Devanbu and M. Gertz and A. Swaminathan},
   title       = {Mining Email Social Networks},
   booktitle   = {Proc.\ of the 3rd Int'l Wksp.\ on Mining Software Repositories},
   year        = 2006,
   pages       = {137--143},
}

@inproceedings{Bird-etal:09a,
   Author      = {C. Bird and P.C. Rigby and E.T. Barr and D.J. Hamilton and D.M. German and P. Devanbu},
   title       = {The Promises and Perils of Mining Git},
   booktitle   = {Proc.\ of the 6th Working Conf.\ on Mining Software Repositories},
   year        = 2009,
}

@inproceedings{Bird-etal:09b,
   Author      = {C. Bird and N. Nagappan and P. Devanbu and H. Gall and B. Murphy},
   title       = {Putting it All Together: Using Socio-Technical Networks to Predict Failures},
   booktitle   = {Proc.\ of the 17th Int'l Sym.\ on Software Reliability Engineering},
   year        = 2009,
}


@inproceedings{Bird-etal:2011,
	Author      = {C. Bird and N. Nagappan and B. Murphy and H. Gall and P. Devanbu},
	Booktitle   = {Proc.\ of the ACM SIGSOFT Sym.\ on the Foundations of Software Engineering},
	Title       = {{Don't Touch My Code! Examining the Effects of Ownership on Software Quality}},
	Year        = {2011},
}

@inproceedings{Canfora-etal:2007,
   author      = {G. Canfora and L. Cerulo and M. {Di Penta}},
   title       = {Identifying Changed Source Code Lines from Version Repositories},
   booktitle   = {Proc.\ of the 4th Int'l Wksp.\ on Mining Software Repositories},
   year        = 2007,
}

@inproceedings{Canfora-etal:2009,
   author      = {G. Canfora and L. Cerulo and M. {Di Penta}},
   title       = {Ldiff: an Enhanced Line Differencing Tool},
   booktitle   = {Proc.\ of the Int'l Conf.\ on Software Engineering},
   year        = 2009,
   pages       = {595--598},
}

@inproceedings{DiPenta-German:2009,
   author      = {M. {Di Penta} and D.M. German},
   title       = {Who are Source Code Contributors and How do they Change?},
   booktitle   = {Proc.\ of the 17th Working Conf.\ on Reverse Engineering},
   year        = 2009,
   pages       = {11--20},
}

@inproceedings{Elbaum-Munson:1998,
   author      = {S. Elbaum and J. Munson},
   title       = {Code churn: A measure for estimating the impact of code change},
   booktitle   = {Proc.\ of the Int'l Conf.\ on Software Maintenance},
   year        = 1998
}

@inproceedings{Fritz-etal:2007,
	Author      = {Fritz, T. and Murphy, G.C. and Hill, E.},
	Title       = {Does a programmer's activity indicate knowledge of code?},
	Booktitle   = {Proc.\ of the ACM SIGSOFT Sym.\ on the Foundations of Software Engineering},
	Pages       = {341--350},
	Year        = {2007},
}

@inproceedings{Gethers-Poshyvanyk:2010
, author       = {M. Gethers and D. Poshyvanyk}
, title        = {Using Relational Topic Models to Capture Coupling among Classes in Object-Oriented Software Systems}
, booktitle    = {Proc. of the Int'l Conf. on Software Maintenance}
, year         = 2010
, pages        = {1--10}
}

@inproceedings{Gethers-etal:11a,
   author      = {M. Gethers and T. Savage and M. {Di Penta} and R. Oliveto and D. Poshyvanyk and A. {De Lucia}},
   title       = {{CodeTopics}: Which Topic Am {I} Coding Now?},
   booktitle   = {Proc.\ of the 33rd Int'l Conf.\ on Software Engineering},
   year        = 2011,
   pages       = {1034--1036}
}

@inproceedings{Gethers-etal:11b,
   author      = {M. Gethers and R. Oliveto and D. Poshyvanyk and A {De Lucia}},
   title       = {On Integrating Orthogonal Information Retrieval Methods to Improve Traceability Link Recovery},
   booktitle   = {Proc.\ of the 27th IEEE Int'l Conf.\ on Software Maintenance},
   year        = 2011,
}

@inproceedings{Girba-etal:2005,
   author      = {T. Girba and A. Kuhn and M. Seeberger and S. Ducasse},
   title       = {How Developers Drive Software Evolution},
   booktitle   = {Proc.\ of the 8th Int'l Wksp.\ on Principles of Software Evolution},
   year        = 2005,
   pages       = {1--10},
}

@inproceedings{Hindle-etal:2009,
   author      = {A. Hindle and M.W. Godfrey and R.C. Holt},
   title       = {What's Hot and What's Not: Windowed Developer Topic Analysis},
   booktitle   = {Proc.\ of the IEEE Int'l Conf.\ on Software Maintenance},
   year        = 2009,
}

@inproceedings{Horwitz:1990,
   author      = {S. Horwitz},
   title       = {Identifying the Semantic and Textual Differences between Two Versions of a Program},
   booktitle   = {Proc.\ of the ACM SIGPLAN Conf.\ on Programming Language Design and Implementation},
   year        = 1990,
   pages       = {234--245},
}

@inproceedings{Linstead-etal:2007,
   author      = {E. Linstead and P. Rigor and S. Bajracharya and C. Lopes and P. Baldi},
   title       = {Mining Eclipse Developer Contributions via Author-Topic Models},
   booktitle   = {Proc.\ of the Int'l Conf.\ on Software Engineering Workshops},
   year        = 2007,
}

@inproceedings{Liu-etal:2005,
   author      = {Y. Liu and E. Stoulia and H. Erdogmus},
   title       = {Understanding the Open-Source Software Development Process: a Case Study with {CVSChecker}},
   booktitle   = {Proc.\ of the 1st Int'l Conf.\ on Open Source Systems},
   year        = 2005,
}

@inproceedings{Lukins-etal:2008
, author       = {S.K. Lukins and N.A. Kraft and L.H. Etzkorn}
, title        = {Source Code Retrieval for Bug Localization using Latent {D}irichlet Allocation}
, booktitle    = {Proc.\ of the 15th Working Conf.\ on Reverse Engineering}
, year         = 2008
, pages        = {155--164}
}

@inproceedings{McDonald-Ackerman:2000,
   author      = {D.W. McDonald and M.S. Ackerman},
   title       = {Expertise Recommender: A Flexible Recomendation System and Architecture},
   booktitle   = {Proc.\ of the ACM Conf.\ on Computer Supported Cooperative Work},
   year        = 2000,
}

@inproceedings{Mockus-Herbsleb:2002,
	Author      = {Mockus, A. and Herbsleb, J.D.},
	Title       = {Expertise browser: a quantitative approach to identifying expertise},
	Booktitle   = {Proc.\ of the 24th Int'l Conf.\ on Software Engineering},
	Pages       = {503--512},
	Year        = {2002},
}

@inproceedings{Mockus:2009,
	Author      = {Mockus, A.},
	Title       = {Succession: Measuring transfer of code and developer productivity},
	Booktitle   = {Proc.\ of the 31st Int'l Conf.\ on Software Engineering},
	Month       = {may},
	Pages       = {67 -77},
	Year        = {2009},
}

@inproceedings{Moser-etal:2008,
   author      = {R. Moser and W. Pedrycz and G. Succi},
   title       = {A Comparative Analysis of the Efficiency of Change Metrics and Static Code Attributes for Defect Prediction},
   booktitle   = {Proc.\ of the Int'l Conf.\ on Software Engineering},
   year        = 2008,
   pages       = {181--190},
}

@inproceedings{Nagappan-Ball:2005,
   author      = {N. Nagappan and T. Ball},
   title       = {Use of Relative Code Churn Measures to Predict System Defect Density},
   booktitle   = {Proc.\ of the Int'l Conf.\ on Software Engineering},
   year        = 2005,
   pages       = {284--292},
}

@inproceedings{Nagappan-etal:2008,
	Author      = {Nagappan, N. and Murphy, B. and Basili, V.},
	Title       = {The influence of organizational structure on software quality: an empirical case study},
	Booktitle   = {Proc.\ of the 30th Int'l Conf.\ on Software Engineering},
	Pages       = {521--530},
	Year        = {2008},
}

@inproceedings{Oliveto-etal:2010
, author       = {R. Oliveto and M. Gethers and D. Poshyvanyk and A. {De Lucia}}
, title        = {On the Equivalence of Information Retrieval Methods for Automated Traceability Link Recovery}
, booktitle    = {Proc. of the IEEE Int'l Conf. on Program Comprehension}
, year         = 2010
, pages        = {68--71}
}

@inproceedings{Pinzger-etal:2008,
	Author      = {Pinzger, M. and Nagappan, N. and Murphy, B.},
	Title       = {Can developer-module networks predict failures?},
	Booktitle   = {Proc.\ of the ACM SIGSOFT Sym.\ on the Foundations of Software Engineering},
	Pages       = {2--12},
	Year        = {2008},
}

@inproceedings{Poshyvanyk-Marcus:2006,
   author      = {D. Poshyvanyk and A. Marcus},
   title       = {The Conceptual Coupling Metrics for Object-Oriented Systems},
   booktitle   = {Proc.\ of the 22nd IEEE Int'l Conf.\ on Software Maintenance},
   year        = 2006,
   pages       = {469--478}
}

@inproceedings{Rahman-Devanbu:2011,
	Author      = {Rahman, F. and Devanbu, P.},
	Title       = {Ownership, experience and defects: a fine-grained study of authorship},
	Booktitle   = {Proceeding of the 33rd Int'l Conf.\ on Software Engineering},
	Pages       = {491--500},
	Year        = {2011},
}

@inproceedings{Savage-etal:2010
, author    = {T. Savage and B. Dit and M. Gethers and D. Poshyvanyk}
, title     = {{TopicXP}: Exploring Topics in Source Code using Latent {D}irichlet Allocation}
, booktitle = {Proc.\ of 26th IEEE Int'l Conf.\ on Software Maintenance}
, year      = 2010
}

@inproceedings{Tian-etal:2009
, author       = {K. Tian and M. Revelle and D. Poshyvanyk}
, title        = {Using Latent {D}irichlet Allocation for Automatic Categorization of Software}
, booktitle    = {Proc. of the 6th IEEE Working Conf. on Mining Software Repositories}
, year         = 2009
, pages        = {163--166}
}

@inproceedings{Ujhazi-etal:2010,
   author      = {B. \'Ujh\'azi and R. Ferenc and D. Poshyvanyk and T. Gyim\'othy},
   title       = {New Conceptual Coupling and Cohesion Metrics for Object-Oriented Systems},
   booktitle   = {Proc.\ of the 10th IEEE Int'l Working Conf.\ on Source Code Analysis and Manipulation},
   year        = 2010,
   pages       = {33--42}
}

@inproceedings{Voinea-etal:2005,
   author      = {L. Voinea and A. Telea and J.J. {van Wijk}},
   title       = {{CVSscan}: Visualization of Code Evolution},
   booktitle   = {Proc.\ of the ACM Sym.\ on Software Visualization},
   year        = 2005,
}

@inproceedings{Voinea-Telea:2006,
   author      = {S.L. Voinea and A. Telea},
   title       = {{CVSgrab}: Mining the History of Large Software Projects},
   booktitle   = {IEEE-VGTC Sym.\ on Visualization},
   year        = 2006,
}

@inproceedings{Wei-Croft:2006
, author       = {X. Wei and W.B. Croft}
, title        = {{LDA}-based document models for ad-hoc retrieval}
, booktitle    = {Proc.\ of ACM SIGIR}
, year         = 2006
}

--TechReport

@techreport{Heinrich:2009
, author       = {G. Heinrich}
, title        = {Parameter Estimation for Text Analysis}
, institution  = {Fraunhofer IGD}
, year         = 2009
, address      = {Darmstadt, Germany}
, month        = sep
, note         = {Version 2.9}
, url          = {http://www.arbylon.net/publications/text-est2.pdf}
}




@inproceedings{Steyvers-etal:2004,
   author      = {M. Steyvers and P. Smyth and M. Rosen-Zvi and and T. Griffiths},
   title       = {Probabilistic author-topic models for information discovery},
   booktitle   = {Proc.\ of the 10th ACM SIGKDD Int'l Conf.\ on Knowledge Discovery and Data Mining},
   year        = 2004,
   pages       = {306--315}
}

@inproceedings{Corley-etal:2011
, author       = {C.S. Corley and N.A. Kraft and L.H. Etzkorn and S.K. Lukins}
, title        = {Recovering traceability links between source code and fixed bugs via patch analysis}
, booktitle    = {Proc. of the 6th Int'l Wksp. on Traceability in Emerging Forms of Software Engineering}
, year         = 2011
, pages        = {31--37}
}
@inproceedings{Marcus-etal:2004
, author       = {A. Marcus and A. Sergeyev and V. Rajlich and J.I. Maletic}
, title        = {An Information Retrieval Approach to Concept Location in Source Code}
, booktitle    = {Proc. of the 11th Working Conf. on Reverse Engineering}
, year         = 2004
, pages        = {214--223}
}
@inproceedings{Marcus-Menzies:2010
, author       = {A. Marcus and T. Menzies}
, title        = {Software is data too}
, booktitle    = {Proc. of the FSE/SDP Wksp. on Future of Software Engineering Research}
, year         = 2010
, pages        = {229--232}
}
@inproceedings{Fluri-etal:2007
, author       = {B. Fluri and M. Wursch and H.C. Gall}
, title        = {Do code and comments co-evolve? {O}n the relation between source code and comment changes}
, booktitle    = {Proceedings of the 14th Working Conference on Reverse Engineering}
, year         = 2007
, pages        = {70--79}
, doi          = {10.1109/WCRE.2007.21}
}
@incollection{StopWords
, author    = {C. Fox}
, title     = {Lexical Analysis and Stoplists}
, booktitle = {Information Retrieval: Data Structures and Algorithms}
, year      = 1992
, editor    = {W.B. Frakes and R. Baeza-Yates}
, publisher = {Prentice-Hall}
, isbn      = {0-13-463837-9}
}
@inproceedings{Maskeri-etal:2008
, author    = {G. Maskeri and S. Sarkar and K. Heafield}
, title     = {Mining business topics in source code using latent {D}irichlet allocation}
, booktitle = {Proc.\ of the 1st India Software Engineering Conference}
, year      = 2008
, pages     = {113--120}
}
@inproceedings{Li-McCallum:2006
, author    = {W. Li and A. McCallum}
, title     = {Pachinko Allocation: {DAG}-Structured Mixture Models of Topic Correlations}
, booktitle = {Proc.\ of the 23rd Int'l Conf.\ on Machine Learning}
, year      = {2006}
}
@article{Deerwester-etal:1990
, author    = {Deerwester, S. and Dumais, S. and Furnas, G. and Landauer, T. and Harshman R.}
, title     = {Indexing by latent semantic analysis}
, journal   = {Journal of the American Society of Information Science}
, year      = 1990
, pages     = {391--407}
}
@inproceedings{Mimno-etal:2007
, author    = {D. Mimno and W. Li and A. McCallum}
, title     = {Mixtures of Hierarchical Topics with Pachinko Allocation}
, booktitle = {Proc.\ of the 24th Int'l Conf.\ on Machine Learning}
, year      = {2007}
}
@incollection{Dig-etal:2006,
   author = {Dig, Danny and Comertoglu, Can and Marinov, Darko and Johnson, Ralph},
   title = {Automated Detection of Refactorings in Evolving Components},
   booktitle = {ECOOP 2006 – Object-Oriented Programming},
   series = {Lecture Notes in Computer Science},
   editor = {Thomas, Dave},
   publisher = {Springer Berlin / Heidelberg},
   isbn = {978-3-540-35726-1},
   keyword = {Computer Science},
   pages = {404-428},
   volume = {4067},
   doi = {10.1007/11785477\_24},
   year = {2006}
}

@article{Ratcliff-Metzener:1988,
   author = {Ratcliff, J.W. and Metzener, D.},
   title = {Pattern matching: The gestalt approach},
   journal = {Dr. Dobb's Journal},
   year = 1988,
   url = {http://drdobbs.com/database/184407970?pgno=5},
}

@inproceedings{Broder:1997,
   author = {A. Broder},
   title = {On resemblance and containment of documents},
   booktitle = {Proc.\ of {SEQUENCES}},
   year = 1997,
   doi = {10.1109/SEQUEN.1997.666900},
}

@inproceedings{Robles-Gonzalez-Barahona:2005,
   author      = {G. Robles and J.M. Gonzalez-Barahona},
   title       = {Developer identification methods for integrated data from various sources},
   booktitle   = {Proc.\ of the Int'l Wksp.\ on Mining Software Repositories},
   year        = 2005
}

@article{Goeminne-Mens:2011,
   author      = {M. G\"ominne and T. Mens},
   title       = {A comparison of identity merge algorithms for software repositories},
   journal     = {Science of Computer Programming},
   year        = 2011
}

@inproceedings{Williams-Spacco:2008,
   author      = {C.C. Williams and J.W. Spacco},
   title       = {Branching and merging in the repository},
   booktitle   = {Proc.\ of the Int'l Wksp.\ on Mining Software Repositories},
   year        = 2008
}
