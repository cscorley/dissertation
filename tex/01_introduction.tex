Program comprehension is a prerequisite to incremental change. A
software developer who is tasked with changing a large software system
spends effort on program comprehension activities to gain the knowledge
needed to make the change\scite{Corbi:89}. For example, the developer
spends effort to understand the system architecture or to locate the
parts of the source code that implement the feature(s) being changed.
Gaining such knowledge can be a time-consuming task, especially for
developers who are unfamiliar with the system. Linguistic topics can
help such developers to understand the system by revealing a latent
structure that is not obvious from the package hierarchy or system
documentation\scite{Savage-etal:10}.

Linguistic topics are clusters of source code entities (e.g., classes)
that are grouped by their natural language content (i.e., the words in
their identifiers, comments, and literals). Such topics often correspond
to the concepts and features implemented by the source
code\scite{Baldi-etal:08}, and exploring such topics shows promise in
helping developers to understand the entities that make up a system and
to understand how those entities
relate\scite{Kuhn-etal:07,Maskeri-etal:08,Savage-etal:10,Gethers-etal:11a}.
Recent approaches to exploring linguistic topics in source code use
machine learning (ML) techniques that model correlations among words,
such as latent semantic indexing (LSI)\scite{Deerwester-etal:90} and
latent Dirichlet allocation (LDA)\scite{Blei-etal:03}, and ML techniques
that also model correlations among documents, such as
RTM\scite{Chang-Blei:10}.

Linguistic topics in source code have many applications in addition to
general program comprehension. These applications include aspect
mining\scite{Baldi-etal:08} and traceability link
recovery\scite{Asuncion-etal:10}. Yet, while researchers have used the
extrinsic properties of topics in software engineering tasks, they have
not yet measured their intrinsic properties. We believe that
understanding these intrinsic properties will lead to a better
understanding of how topics are implemented and thus will lead to a
better understanding of how topics relate to each other and to source
code entities such as packages or classes.

Software developers are often confronted with maintenance tasks that
involve navigation of repositories that preserve vast amounts of project
history. Navigating these software repositories can be a time-consuming
task, because their organization can be difficult to understand.
Fortunately, topic models such as \abbr{LDA}{latent Dirichlet
allocation}\scite{Blei-etal:2003} can help developers to navigate and
understand software repositories by discovering topics (word
distributions) that reveal the thematic structure of the
data\scite{Linstead-etal:2007,Thomas-etal:2011,Hindle-etal:2012}.

When modeling a source code repository, the corpus typically represents
a snapshot of the code. That is, a topic model is often trained on a
corpus that contains documents that represent files from a particular
version of the software. Keeping such a model up-to-date is expensive,
because the frequency and scope of source code changes necessitate
retraining the model on the updated corpus. However, it may be possible
to automate certain maintenance tasks without a model of the complete
source code. For example, when assigning a developer to a change task, a
topic model can be used to associate developers with topics that
characterize their previous changes. In this scenario, a model of the
changesets created by each developer may be more useful than a model of
the files changed by each developer. Moreover, as a typical changeset is
smaller than a typical file, a changeset-based model is less expensive
to keep current than a file-based model.

Toward the goal of automating software maintenance tasks using
changeset-based models, in this paper we qualitatively compare topic
models trained on corpora of changesets to those trained on files. For
our comparison we consider vocabulary measures, which indicate whether
term distributions in the changeset corpora match those in the file
corpora, and topic
distinctness\scite{Wei-etal:2010,Thomas-etal:2011,Chuang-etal:2012},
which measures how distinct one topic in a model is from another. Models
with higher topic distinctness values are desirable, because distinct
topics are more useful in differentiating among the documents in a
corpus than are similar topics.

\section{Information Retrieval in Software
Maintenance}\label{information-retrieval-in-software-maintenance}

\section{Motivation}\label{motivation}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Software evolves quickly
\item
  Current file-based models do not keep up-to-date models
\item
  Keeping them up-to-date involves:

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    Rebuilding at every commit (slowest)
  \item
    Rebuilding at intervals (data loss)
  \item
    Modify the model internally using heuristics
  \end{itemize}
\item
  In FLTs, file-based models are easy and natural, but not necessary to
  build the model.
\item
  In triaging, file-based models do not capture the appropriate
  information, e.g., the developer's topics.
\item
  Models can be built from any text input. We do not need to use the
  files as a proxy. The word occurrences will still occur in changesets!
\end{itemize}

\section{Research goals}\label{research-goals}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  To evaluate models built on changesets to other models (typically
  based on files only, but may include additional information)
\item
  Provide a practical framework for building models that can be used in
  multiple contexts (FLT, bug localization, triage).
\item
  Provide insight for researchers and tool developers on best practices
  for using changeset-based models
\end{itemize}

\section{Outline}\label{outline}

In this proposal we propose an approach towards building practical,
online topic models for automating software maintenance tasks. In
Chapter\sref{ch:related} we discuss the background and related works.
Chapter\sref{ch:previous} covers previous work already achieved towards
the research goals. Chapter\sref{ch:proposed} outlines the primary
studies and their evaluations, along with supporting studies. A
projected schedule for completion of these studies is given in
Chapter\sref{ch:schedule}. Finally, we conclude this proposal in
Chapter\sref{ch:conclusion}.
